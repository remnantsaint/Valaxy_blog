---
layout: post
title: 使用Apriori算法进行关联分析
date: 2024-09-24 09:08:42
cover: 
top: 
tags: 
  - 机器学习
categories: 
  - 人工智能
  - 机器学习
# author: @Remsait
---
## 关联分析
&emsp; 关联分析是一种在大规模数据集中寻找有趣关系的任务，这些关系可以有以下两种形式  
- 频繁项集：经常出现在一块的物品的集合
- 关联规则：按时两种物品之间存在很强的关系

## 相关术语
- 关联分析（关联规则学习）：从大规模数据集中寻找物品间的隐含关系被称作`关联分析`或者`关联规则学习`，下面是用一个杂货店的例子来说明这两个概念，如下图所示
![](https://cdn.jsdelivr.net/gh/remnantsaint/hexoImage@main/202409240920933.png)
- 频繁项集：{葡萄酒，尿布，豆奶}就是一个频繁项集的子集
- 关联规则：尿布 -> 葡萄酒 就是一个而关联规则，这意味着顾客如果买了尿布，那么他很可能会买葡萄酒。
>`频繁`的定义是什么呢？怎么样才算频繁呢？度量他们的方法有很多种，这里我们来简单的介绍下支持度和可信度。

- 支持度：数据集中包含该项集的记录所占的比例。例如上图中，{豆奶}的支持度为 4/5。{豆奶，尿布}的支持度为 3/5。
- 可信度：针对一条诸如{尿布} -> {葡萄酒} 这样的具体关联规则来定义的。这条规则的`可信度`被定义为`支持度（{尿布，葡萄酒}）/ 支持度（{尿布}）`，从图中可以看出支持度({尿布, 葡萄酒}) = 3/5，支持度({尿布}) = 4/5，所以 {尿布} -> {葡萄酒} 的可信度 = 3/5 / 4/5 = 3/4 = 0.75。

&emsp; `支持度` 和 `可信度` 是用来量化 `关联分析` 是否成功的一个方法。 假设想找到支持度大于 0.8 的所有项集，应该如何去做呢？ 一个办法是生成一个物品所有可能组合的清单，然后对每一种组合统计它出现的频繁程度，但是当物品成千上万时，上述做法就非常非常慢了。 我们需要详细分析下这种情况并讨论下 Apriori 原理，该原理会减少关联规则学习时所需的计算量。

## Apriori 原理
&emsp; 假设我们有四个商品：商品0、商品1、商品2、商品3。那么从左到右所有组合的可能有$2^N - 1 = 2^4 - 1 = 15$，其中包括{01,02,...012,013...0123}。随着物品的增加，计算次数呈指数增长  
&emsp; 为了降低计算次数和时间，研究人员发现了一种所谓的 Apriori 原理，即某个项集是频繁的，那么它所有的子集也是频繁的。例如，如果{0，1}是频繁的，那么{0}，{1}也是频繁的，该原理直观上没有什么帮助，但是反过来看（逆否）就有用了，也就是说如果一个项集是`非频繁项集`，那么它所有超集也是非频繁项集。  

&emsp; 已知 {2,3} 是 非频繁项集，那么利用上面的知识，我们就可以知道 {0,2,3} {1,2,3} {0,1,2,3} 都是 非频繁的。 也就是说，计算出 {2,3} 的支持度，知道它是 非频繁 的之后，就不需要再计算 {0,2,3} {1,2,3} {0,1,2,3} 的支持度，因为我们知道这些集合不会满足我们的要求。 使用该原理就可以避免项集数目的指数增长，从而在合理的时间内计算出频繁项集。 

### Apriori 算法优缺点
```text
* 优点: 易编码实现
* 缺点: 在大数据集上可能较慢
* 适用数据类型: 数值型 或者 标称型数据。
```

### Apriori 算法流程步骤
```text
* 收集数据: 使用任意方法。
* 准备数据: 任何数据类型都可以，因为我们只保存集合。
* 分析数据: 使用任意方法。
* 训练数据: 使用Apiori算法来找到频繁项集。
* 测试算法: 不需要测试过程。
* 使用算法: 用于发现频繁项集以及物品之间的关联规则。
```





















## Reference
<https://github.com/apachecn/ailearning/blob/master/docs/ml/11.md>