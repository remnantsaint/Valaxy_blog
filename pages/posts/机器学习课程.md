---
layout: post
title: 机器学习课程
date: 2024-10-31 14:54:08
cover: 
top: 
tags: 
categories: 
  - 人工智能
# author: @Remsait
---
### 1.2 数据获取
采集数据的方法：1.在各种网站爬取。2.子集采集数据  

找数据集：
- Paperswithcodes Datasets   论文中的数据集
- Kaggle Datasets   机器学习竞赛的数据集
- Google Dataset search   在谷歌上搜索
- 等等
可用学术数据集、竞赛数据集、原始数据集

### 1.3 网页数据抓取
数据抓取是指手机网页上特定的有价值的数据  
先爬取 html 网页，然后用 BeautifulSoup 包来抓取特定的信息  
最终变成一个个数学列表  

爬公开的网页信息，不爬有版权的信息

### 1.4 数据标注
提高数据的质量  

找标注工做标注  

没钱就弱监督学习，半自动生成标号

总结：标注的三个方法：
1. 自训练：已经有一些样本的标号，不断地去训练模型，把模型在没有标号的数据上预测较准的数据放到标注集中，不断的迭代。（标注比较简单的数据）
2. 众包（标注比较难的数据）
3. 弱监督学习

### 2.1 探索性数据分析
分析一个住房数据：
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
import seaborn as sns
fromt IPython import display
# svg 拥有高分辨率
display.set_matplotlib_formats('svg')

# 住房信息存为csv文件，并且经过压缩也能识别
data = pd.read_csv('house_sales.zip')

# data.shape 命令能获取 data 的维度
data.shape

# 打印前面几行
data.head()

# 会发现脏数据有很多的缺失或者错误数据

# 显示缺失率小于0.3的列
null_sum = data.isnull().sum()
data.columns[null_sum < len(data) * 0.3]

# 删除缺失率大于0.3的列
data.drop(columns = data.columns[null_sum > len(data) * 0.3], inplace = True)

# 查看数据类型,很多需要进行数据转换（数据清洗）
data.dtypes

# 遍历这几个列，将$和-删去，将空串替换成NaN，把数字类型转换为 float
# r''表示''内的字符串不会被转义，^\s*$ 正则表示空串
currency = ['Sold Price','Listed Price','Tax assessed value','Annual tax amount']
for c in currency:
	data[c] = data[c].replace(
		r'[$,-]','',regex = True).replace(
		r'^\s*$',np.nan, regex = True).astype(float)

# 遍历这两个列，看是否有 Acres 单位，删去可能存在的 sqft Acres , 这三个，并更改数据类型，然后将有 Acres 单位的值乘43560
# \b 是单词边界，使其精准匹配
areas = ['Total interior livable area','Lot size']
for c in areas:
	acres = data[c].str.contains('Acres') ==True
	col = data[c].replace(r'\b sqft\b|\b Acres\b|\b,\b','',regex = True).astype(float)
	col[acres] *= 43560
	data[c] = col

# 列出每个列的综合、最小、方差等，看看噪声
data.describe()

# abnormal为异常，过滤掉不正常面积的房子
abnormal = (data[areas[1]] <10) | (data[areas[1]] > 1e4)
data = data[~abnormal]
sum(abnormal)

# 画出直方图，%.0e指用科学计数法表示，xlim是x轴范围，xticks是x轴刻度，xticklabels是x轴标签
ax = sns.histplot(np.log10(data['Sold Price']))
ax.set_xlim([3,8])
ax.set_xticks(range(3,9))
ax.set_xticklabels(['%.0e'%a for a in 10**ax.get_xticks()])

# 把房子的类别的值打印出来，前20行
data['Type'].value_counts()[0:20]

# 画出房价核密度估计图（KDE）
types = data['Type'].isin(['SingleFamily','Condo','MultiFamily','Townhouse'])
sns.displot(pd.DataFrame({'Sold Price':np.log10(data[types]['Sold Price']),'Type':data[types]['Type']}), x='Sold Price', hue='Type', kind = 'kde')

# 计算每平方英尺的售价，存储在新类，绘制箱线图
data['Price per living sqft'] = data['Sold Price'] / data['Total interior livable area']
ax = sns.boxplot(x='Type', y='Price per living sqft', data=data[types], fliersize=0)
ax.set_ylim([0,2000]);
```

### 2.2 数据清洗
之前讲过了数据收集、数据标注  
本节讲如何提高数据质量，即数据的清理，用于处理噪声很多  

数据错误的类型：  
Outliers: 数据的值不在范围内  
Rule violations: 规则性问题，存在冲突  
Pattern violations: 违反语义和语法等约束，如对齐、格式化、拼写错误   

对于类别的outliers问题，可以手动的修正、丢弃；对于数值大小的问题，可以通过看箱线图来舍弃  
对于Rule violations规则性问题，可以自己总结一些规则  
对于pattern violations模式问题，也是根据规则来看，这两种问题都要不断地去看数据哪个地方不对，然后总结出规律，再去修改   

### 2.3 数据变换
数据标注清理之后，特征工程之前，要进行数据变换  

对于扁平数据（Tabular Data）来说
1. 把一个列的最大值和最小值限定在一个区间内，把所有原始值通过线性变换进来。假设设置最大值为b，最小值为a，则公式为$x_i' = \frac{x_i - min_x}{max_x - min_x} (b-a) + a$  
2. Z-score 方法，将均值为 0，方差为 1，x 减去均值再除以方差，公式为$x_i' = \frac{x_i - mean(x)}{std(x)}$。最常见
3. $x_i' = x_i / 10^j$ ，使$x_i'$全部小于 1
4. $x_i' = log(x_i)$ 。比较常用

对于图片来说，存储图片很贵，要把图片尺寸变小。
1. 下采样，缩小图片大小。
2. 用 jpeg 格式存
3. 用降维方法，模型可能收敛更快

对于视频来说
1. 删除对机器学习来说没用的片段
2. 用压缩算法，但可能导致视频读取解码出现问题
3. 把视频变成很多帧图片

对于文本来说
1. 词根化、语法化，把单词换成常见的形式，比如把is am are 换成 be
2. 把单词用空格切出来一个个词元

总结：数据变化只是格式上的变化，变换成机器学习能用的格式。不压缩的话很贵，压缩太多的话会导致精度的降低

### 2.4 特征工程
把数据转化成模型喜欢的输入，机器学习一般是人工的抽取特征让机器学习，深度学习一般是用神经网络的特征学习  

1. Tabular Data Features：
	- 整数型和浮点型直接用或者切成 n 个子区间
	- 分类数据，每列代表一个类别，每一行只有一个 1 表示对应，其他全为 0，只保留有用的类，其他设置为 unknown
	- 时间特征
	- 将特征组合起来，笛卡尔积

2. 文本数据Text Features
	- bag of words (BoW)
	- word Rmbeddings (word2vec)
	- Pre-trained language models (BERT,GPT-3)  用预训练的语言模型

3. 图片/视频数据
	- 以前手动提取特征
	- 现在用预训练好的深度神经网路，例如 ResNet 模型和 I3D 模型

### 2.5 数据章节总结
从一个机器学习任务开始
1. 有足够的数据？收集数据
2. 优化数据标号？数据标注
3. 优化数据质量？数据清洗、数据变换、特征工程
4. 优化模型？
5. 1->2->3->4->1   迭代完成

权衡数据的质量和数量，保证数据的多样性，安全性

### 3.1 机器学习介绍
监督学习、半监督学习、无监督学习、强化学习（跟环境交互，像人类学习方法，不断尝试）  

监督学习：
1. 模型model，将输入转变成输出
2. 损失函数loss，衡量预测出来的值和真实值之间的差别，例如$(预测值 - 真实值)^2$ 就是平方损失
3. 目标函数，训练过程中需要优化的任何函数，例如最小化样本损失的和
4. 优化，通过求解目标函数来学习模型参数

监督学习模型分类：决策树、线性模型、核方法、神经网络

### 3.2 决策树
把数据放到根节点，最后走到叶结点得到标号  

优点：**可解释的**；可以处理数值和分类特征  
缺点：非常不稳定，容易被噪音影响；给一个复杂的数据导致过拟合；在计算上不容易并行化，效率低  

随机森林，使决策树变稳定：
1. 训练多个树来改善稳定性，每棵树独立训练，多数投票用于分类，平均投票用于回归
2. 随机性从何而来？在训练集随机采样出样本，之后再随机替换样本；随机采样一些特征  

基于梯度增强决策树（Gradient Boosting Decision Trees）：
1. 训练多棵树，不是独立的训练，而是顺序的训练，新的树是拿之前树预测不准的地方接着去拟合
2. 在步骤 t = 1.....时，用$F_t(x)$表示过去训练树的综合，则训练一个新树$f_t$的残差为$\{(x_i, y_i - F_t(x_i))\}_{i=1,...}.$，且$F_{t+1}(x) = F_t(x) + f_t(x)$
3. 如果使用均方作为损失函数，残差等于$-\frac{\partial L}{\partial F}$，因此称为梯度增强

### 3.3 线性模型（）
假设有三个特征：$x_1 , x_2 , x_3$，那么预测值为加权和：$y = w_1x_1 + w_2x_2 + w_3x_3 + b$，也就是$<w,x> + b$  
目标函数是优化平均均方误差（MSE）  





### Reference
斯坦福21秋季：实用机器学习