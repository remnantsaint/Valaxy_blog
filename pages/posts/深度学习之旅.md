---
layout: post
title: 深度学习之旅
date: 2025-03-03 13:18:03
updated: 2025-09-15 
time_warning: true
cover: 
top: 
tags: 
 - 深度学习
categories: 
 - 深度学习
# author: @Remsait
---
## 环境准备
  首先要在jupyter上能进行`import pytorch`，实验室电脑不支持CUDA，所以下CPU版的pytorch  
```bash
#先创建环境
  conda create -n pytorch python=3.6 -y
  activate pytorch
#安装CPU版pytorch
  conda install pytorch torchvision cpuonly -c pytorch
#安装 Jupyter 并让 mytorch 在 Jupyter Notebook 中可用
  conda install jupyter -y
#重新启动jupyter并选择已存在内核
```
  注意不要既用`conda`来安装包，又用`pip`安装包，会导致依赖发生问题  

  在 Anaconda prompt 中输入 `jupyter notebook D:` 就能打开了  
  用 jupyter 前先在Anaconda中切换到pytorch环境，再打开 jupyter 换内核
```python
import sys
import torch
# 查看Python版本
print(f"Python版本: {sys.version}")
# 查看PyTorch版本
print(f"PyTorch版本: {torch.__version__}")
# 查看当前Python解释器路径（确认是否为目标环境）
print(f"Python解释器路径: {sys.executable}")
```
## 基本知识
  `dir()`函数能让我们知道工具箱，以及工具箱中都有什么东西，比如 dir(torch)  
  `help()`函数能让我们知道每个工具的使用方法,比如 help(torch.cuda.is_available)  

  运行 python 代码的三种方式：python文件、pycharm python console、jupyter notebook  
### Python 中魔法方法的用法
  __call__ 是 python 中的魔法方法，可以让类的实例具备像函数一样被调用的能力  
  比如定义一个 person = Person() 的实例，用 `person()` 就能调用 __call__ 方法  
  
  __init__ 是初始化方法，在最初的 person = Person() 的 () 内可以输出参数来初始化  
  
  可以自己重写一些魔法方法再应用
## PyTorch 加载数据
  两个类：Dataset , Dataloader  
  
  Dataset 提供一种方式去获取数据及其 label  
  Dataloader 为后面网络提供不同的数据形式  
`read_data.py`代码如下：
```python
from torch.utils.data import Dataset
from PIL import Image
import os

class MyData(Dataset):
    def __init__(self, root_dir, label_dir): # 初始化定义一些变量
        # root_dir = "dataset/train"  label_dir = "ants"
        # 这样组合是为了更好的分开蚂蚁和蜜蜂，也就是标签
        self.root_dir = root_dir
        self.label_dir = label_dir
        self.path = os.path.join(self.root_dir, self.label_dir)
        self.img_path = os.listdir(self.path) # 从文件夹内容获取列表 img_path

    # __开头和结尾的都是魔法方法，不用调用，在初始化时会自动调用
    def __getitem__(self, idx):
        img_name = self.img_path[idx]
        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name) # 图像的文件路径
        img= Image.open(img_item_path) # 打开图像
        label= self.label_dir
        return img, label  # 返回单个图像和其标签

    def __len__(self):
        return len(self.img_path) # len(列表) 返回列表的长度

root_dir = "data/hymenoptera_data/train"
ants_label_dir = "ants"
bees_label_dir = "bees"
ants_dataset = MyData(root_dir, ants_label_dir) # 创建一个蚂蚁数据集
bees_dataset = MyData(root_dir, bees_label_dir) # 创建一个蜜蜂数据集
'''
ants_dataset[0][0].show() # 第一个0是索引，指第一个文件；第二个0是自动返回的img，
print(ants_dataset[0][1]) # [0][1]就是label
'''
img, label = ants_dataset[0]
img.show()

train_dataset = ants_dataset + bees_dataset 
# 只有定义了__len__方法，才能相加
# 顺序是前后两个数据集的拼接
print(len(train_dataset))
```
## TensorBoard 的使用
### TensorBoard 安装
  `conda install tensorboard -y`
### 使用
  首先安装 opencv ：`conda install -c conda-forge opencv -y`  

  PIL提取的文件类型不符合`add_image()`函数的要求，但是 opencv 符合（可以用 numpy 把 PIL 提取的转变为 array  

`test_tb.py`代码如下：  
```python
from torch.utils.tensorboard import SummaryWriter
import numpy as np
from PIL import Image
import os

writer = SummaryWriter("logs") # 创建日志文件夹
# 在终端用 tensorboard --logdir=logs --port=6007 运行查看

image_path = os.path.join("data", "train", "ants_image", "0013035.jpg")
img_PIL = Image.open(image_path)
img_array = np.array(img_PIL)
writer.add_image("test", img_array, 1, dataformats='HWC') # 添加图像
# 用 HWC 是因为 array 的 shape 中通道是最后一个参数
# 如果换张图片再运行，网页就能看到 step2 是第二张图片了

for i in range(100):
    writer.add_scalar("y=3x", 3*i, i) # 第一个参数是标签，第二个参数是 y，第三个参数是 x

# 左上角切换 scalars 和 images

writer.close()

# 观察训练时候，给 model 用了哪些数据，或者对 model 测试时看每一阶段的输出结果
```
## torchvision 中的 transforms
  trasforms 主要是对图片进行一些变换
### 结构及用法
  先创建一个具体的工具，比如 tool = transforms.ToTensor()  
  然后用这个 tool ：result = tool(imput)  
```python
from PIL import Image
from torchvision import transforms
from torch.utils.tensorboard import SummaryWriter

"""
python 的用法 -> tensor数据类型
通过 transforms.ToTensor 去解决两个问题

2. 为什么需要 Tensor 数据类型
深度学习模型无法直接处理 PIL 图像/python 数组，必须输入torch.Tensor类型
tensor 支持GPU加速、自动求导,并且"C H W"格式更符合计算逻辑
"""
# 绝对路径 E:\tobebetter\learn_pytorch\data\train\ants_image\0013035.jpg
# 相对路径 data\train\ants_image\0013035.jpg
img_path = "data/train/ants_image/0013035.jpg"
img = Image.open(img_path)

writer = SummaryWriter("logs")

# 1. transforms 应该如何使用
tensor_trans = transforms.ToTensor()
tensor_img = tensor_trans(img)
# 输出图片的张量，三通道，每个通道每个元素是一个像素的归一化值

writer.add_image("Tensor_img", tensor_img)

writer.close()
```
### 常见的 Transforms
  Image.open() 输入的是 PIL 格式  
  ToTensor() 输出的是 tensor 张量
  cv.imread() 输出的是 narrays 格式
  
  方法中有 `ToTensor()、Normalize()、Resize()、Compose()`，具体使用方法如代码所示：
```python
from PIL import Image
from torchvision import transforms
from torch.utils.tensorboard import SummaryWriter

writer = SummaryWriter("logs")
img = Image.open("E:\\tobebetter\\learn_pytorch\\data\\train\\ants_image\\0013035.jpg")
# print(img)   size = 768 × 512 宽 高

"""
oooo = transforms.xxxx()都是创建一个xxxx实例 并用__init__初始化
yyyy = oooo(kk)就是调用 __call__ 方法
用 ctrl+左键 来查看官方文档的说明 输入的参数看__init__默认的不用输 变量需要输入
"""

# ToTensor() 使用方法 转换为张量
trans_totensor = transforms.ToTensor()
img_tensor = trans_totensor(img)
# print(img_tensor.shape) shape = 3 512 768 通道 高 宽
# print(img_tensor)
writer.add_image("totensor", img_tensor)
print("——————————————")

# Normalize() 使用方法 标准化
# output[channel] = (input[channel] - mean[channel]) / std[channel]  三通道对应分别计算
# mean 是均值， std 是标准差，Normalize()的参数就是均值和标准差
trans_norm = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
img_norm = trans_norm(img_tensor)
# print(img_norm)
# img_tensor 是图像的张量，数值分布是 [0, 1]
# img_norm 是图像的张量标准化后，数值分布是 均值为0，标准差为1 
print(img_tensor[0][0][0])
print(img_norm[0][0][0])
writer.add_image("norm", img_norm)
# 未标准化前的tensor图像因为比例相同，图像没啥变化
# 标准化后每个像素都改变了，所以肉眼看颜色变化了，但是方便计算机识别
print("——————————————")

# Resize() 使用方法 改变高和宽
print(img.size)
trans_resize = transforms.Resize((768, 512)) # 高 宽
# img PIL -> resize -> img_resize PIL
img_resize = trans_resize(img)
# img_resize PIL -> totensor -> img_resize tens-or
img_resize = trans_totensor(img_resize)
print(img_resize.shape)
print("——————————————")

# Compose() 使用方法，合并功能，按写的transforms变换0列表执行流程
# compose() 需要一个包含 transforms类型的列表
trans_resize_2 = transforms.Resize((800,400)) # 只有一个参数x,将图片短边缩放至x,长宽比不变
trans_compose = transforms.Compose([trans_resize_2, trans_totensor])
img_resize_2= trans_compose(img)
print(img_resize_2.shape)
writer.add_image("Compose", img_resize_2, 1)

# RandomCrop() 使用方法 随机裁剪
trans_random = transforms.RandomCrop(50) # 随机裁剪 50×50 像素的正方形区域，如果指定两个值(50,100)就是高和宽
trans_compose_2 = transforms.Compose([trans_random, trans_totensor]) # 裁剪完变成张量
for i in range(10):
    img_crop = trans_compose_2(img)
    writer.add_image("Random", img_crop, i)

writer.close()
```
## torchvision 中的数据集使用
### datasets 的使用
  使用 torchvision 中的 datasets工具包，能自己下载官方有的数据集  
代码如下：  
```python
from torchvision import transforms, datasets
from torch.utils.tensorboard import SummaryWriter

dataset_transform = transforms.Compose([
    transforms.Resize((512,512)),
    transforms.ToTensor()
])
# train=True代表划分的是训练集，false代表是测试集   transform参数是用到的变换
train_set = datasets.CIFAR10("./dataset", train=True, download=True, transform=dataset_transform)
test_set = datasets.CIFAR10("./dataset", train=False, download=True, transform=dataset_transform)

# img, target = test_set[0]
# print(test_set.classes)
# print(target) # 标签
# print(test_set.classes[target])
# img.show()

writer = SummaryWriter("logs")
# tensorboard --logdir=logs
for i in range(10):
    img, target = test_set[i]
    writer.add_image("test_set", img, i) # img已经转换为了张量

writer.close()
```
## DataLoader 的使用
  datasets 只是告诉我们数据集的位置，dataloader 能将数据加载到神经网络中  
```python
from torch.utils.data import DataLoader
from torch.utils.tensorboard.writer import SummaryWriter
from torchvision import datasets, transforms

# 准备的测试集
test_data = datasets.CIFAR10("./dataset", train=False, download=True, transform=transforms.ToTensor())

# num_workers=0单进程 drop_last=False最后数据不够batch数量是否丢弃
# shuffle=True打乱每轮 Epoch 顺序
test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=True, num_workers=0, drop_last=False)

# 测试数据集中第一张图片及target\
img, target = test_data[0] # getitem() 方法直接返回 img 和 target
print(img.shape)
print(target)

writer = SummaryWriter("logs")
# test_loader设置批数量后，imgs targets 会进行打包
# TensorBoard 不会显示所有的 step，为了节省显存和前端性能，它会进行采样，只显示部分 step
for epoch in range(2):
    step = 0
    for data in test_loader:
        imgs, targets = data
        # print(imgs.shape) # 第一个值是 batch_size 大小
        # print(targets)
        # imgs 形状为 (N, C, H, W)，用于批量可视化应使用 add_images
        writer.add_images("Epoch: {}".format(epoch), imgs, step)
        step += 1

writer.close()
```
## 神经网络的基本骨架——nn.Module的使用

