---
layout: post
title: 利用SVD简化数据
date: 2024-09-27 08:05:33
cover: 
top: 
tags: 
  - 机器学习
categories: 
  - 人工智能
  - 机器学习
# author: @Remsait
---
## SVD（奇异值分解） 概述
&emsp; 提取信息的一种方法，可以把 SVD 看成是从噪声数据中抽取相关特征。奇异值相当于方阵中的特征值，奇异值分解相当于方阵中的特征值分解。从生物信息学到金融学，SVD 是提取信息的强大工具。
## SVD 场景
### 信息检索
&emsp; 隐性语义索引：矩阵 = 文档 + 词语
- 是最早的 SVD 应用之一，我们称利用 SVD 的方法为隐性语义索引（LSI）或隐性语义分析（LSA）  

&emsp; 推荐系统
1. 利用 SVD 从数据中构建以恶搞主题空间
2. 在该空间下计算其相似度。（从高维 - 低维空间的转化，在低维空间来计算相似度，SVD 提升了推荐系统的效率

&emsp; 图像压缩
- 例如：`32*32=1024 => 32*2+2*1+32*2=130` （$2 * 1$表示去掉了除对角线的0），几乎获得了10倍的压缩比。

## SVD 原理
### SVD 工作原理
&emsp; 矩阵分解
- 矩阵分解是将数据矩阵分解为多个独立部分的过程
- 矩阵分解可以将原始矩阵表示成新的易于处理的形式，这种新形式是两个或多个矩阵的乘积。（类似代数中的因果分解）

&emsp; SVD 是矩阵分解的一种类型，也是矩阵分解中最常见的技术
- SVD 将原始数据集矩阵 Data 分解成三个矩阵：U、$\sum$ 、V
- 举例：如果原始矩阵 $Data_{m*n}$ 是m行n列
	- $U_{m*k}$ 表示m行k列
	- $\sum_{k*k}$ 表示k行k列
	- $V_{k*n}$ 表示k行n列  

$$Data_{m*n} = U_{m*k}\sum_{k*k}^{}V_{k*n}$$
![](https://cloudflare.remsait.com/img/%E7%9F%A9%E9%98%B5SVD.png)

&emsp; 下图是实际分解举例
![](https://cloudflare.remsait.com/img/SVD2.png)
- 上述分解中会构建出以恶搞矩阵 $\sum$，该矩阵只有对角元素，其他元素均为0 。另一个惯例就是：$\sum$ 的对角元素是从大到小排列的，这些对角元素称为奇异值。
- 奇异值与特征值（PCA 数据中重要特征）是有关系的，这里的奇异值就是矩阵 $Data * Data^T$ 特征值的平方根。
- 普遍的事实：在某个奇异值的数目（r 个 => 奇异值的平方和累计到总值的 90% 以上）之后，其他的奇异值都置为0（近似于0）。这意味着数据集中仅有 r 个重要特征，而其余特征则都是噪声或冗余特征。

### SVD 算法特点
- 优点：简化数据，去除噪声，优化算法的结果
- 缺点：数据的转化可能难以理解
- 使用的数据类型：数值型数据

## 推荐系统
### 推荐系统 概述
推荐系统是利用电子商务网站向客户提供商品信息和建议，帮助用户决定应该购买什么产品，模拟销售人员帮助客户完成购买过程

### 推荐系统 场景
1. Amazon 会根据顾客的购买历史向他们推荐物品
2. Netflix 会向用户推荐电影
3. 新闻网站会对用户推荐新闻频道

### 推荐系统 要点
&emsp; 基于协同过滤的推荐引擎
- 利用 Python 实现 SVD （Numpy 有一个 linalg 的线性代数工具箱）
- 协同过滤：是通过将用户和其他用户的数据进行对比来实现推荐的
- 当知道了两个用户或两个物品之间的相似度，我们就可以利用已有的数据来预测未知用户的喜好

&emsp; 基于物品的相似度和基于用户的相似度：物品比较少则选择物品相似度，用户比较少则选择用户相似度
- 基于物品的相似度：计算物品之间的距离（耗时会随着物品数量的增加而增加）
- 例如：由于物品A和物品C的相似度很高，所以给买A的人推荐C
- 基于用户的相似度：计算用户之间的距离（耗时会随着用户数量的增加而增加）
- 例如：由于用户A和用户C的相似度很高，所以A和C是兴趣相投的人，对于C买的物品就会推荐给A

&emsp; 相似度计算（略）

&emsp; 推荐系统的评价
- 采用交叉测试的方法（拆分数据集为训练集和测试集）
- 推荐引擎评价的指标：最小均方根误差，也称标准误差，就是计算均方误差的平均值然后取其平方根。
	- 如果RMSE = 1，表示相差 1 个星级；如果RMSE = 2.5，表示相差 2.5 个星级

### 推荐系统 原理
- 推荐系统的工作过程：给定以恶搞用户，系统会为此用户返回 N 个最好的推荐菜
- 实现流程大致如下：
	1. 寻找用户没有评级的菜肴，即在用户-物品矩阵中的 0 值
	2. 在用户没有评级的所有物品中，对每个物品预计一个可能的评级分数。这就是说：我们认为用户可能会对物品的打分（这就是相似计算的初衷）
	3. 对这些物品的评分从高到低进行排序，返回前 N 个物品。






















## Reference
<https://github.com/apachecn/ailearning/blob/master/docs/ml/14.md>