---
layout: post
title: ACDC-NN 文献精读
date: 2025-10-21 08:47:29
updated: 2025-10-21
time_warning: true 
cover: 
top: 
tags: 
 - ddg
categories: 
 - 生物信息
# author: @Remsait
---
# 一种用于预测蛋白质变体自由能变化的反对称神经网络
  [An antisymmetric neural network to predict free energy changes in protein variants](https://iopscience.iop.org/article/10.1088/1361-6463/abedfb)
## 摘要
  蛋白质残基变异后自由能变化的预测是生物物理学和生物医学中的一个重要应用。迄今为止，已开发出多种方法来解决这一问题，包括基于物理原理和机器学习的模型。然而，目前大多数计算工具，特别是数据驱动的方法，未能纳入反对称的基本热力学原理：从野生型到蛋白质结构突变体的变异（XW → XM）与其逆向过程（XM → XW）的自由能差值必须符号相反：∆∆GWM = −∆∆GMW。在此，我们构建了一种深度神经网络系统，该系统在结构上即满足反对称特性。我们证明，新方法（ACDC-NN）在正向和反向变异上的表现优于或相当于其他最先进的方法，使该方法适用于在保持反对称性的同时对新蛋白质变体进行评分。代码可在以下网址获取：https://github.com/compbiomed-unito/acdc-nn
## 引言
  蛋白质稳定性的破坏及其正常功能的丧失与多种疾病相关。蛋白质稳定性的扰动也可能导致单倍剂量不足基因的功能丧失。通常，蛋白质的正常活性是通过在几个代表解折叠自由能局部最小值的折叠结构之间转换来实现的。这些局部最小值可能受到一个或多个非同义DNA变异的影响，这些变异能够改变氨基酸序列，从而增加或降低蛋白质的稳定性。研究非同义变异对蛋白质稳定性影响的主要实验指标是突变型蛋白质结构与其野生型之间的解折叠吉布斯自由能差（∆∆G）（∆∆G = $∆G_M$ −$∆G_W$）。∆∆G的预测在蛋白质工程以及非同义DNA变异的解读中具有重要意义。

  ∆∆G的准确预测仍然是一个尚未解决的挑战，迄今为止已开发出多种计算工具来应对这一问题。然而，正如近期研究所指出的，目前大多数方法由于缺乏反对称预测而存在偏差。∆∆G的反对称性可概括如下：给定野生型（W）和突变型（M）的蛋白质结构，二者仅在位置 X 处的一个残基上有所不同，那么量值 $\Delta\Delta G_{WM} = \Delta G_M − \Delta G_W$ 表示由氨基酸替换 $X_W → X_M$ 引起的蛋白质稳定性变化。同样地，考虑到分子体系M与W之间的对称性，对于反向变异 $X_M → X_W$，相应的吉布斯自由能变化应具有相反的符号：$\Delta\Delta G_{WM} = -\Delta\Delta G_{MW}$  

  这是由于连接展开（U）和折叠（F）状态的热力学规则，该规则在平衡状态下可由以下关系描述：
$$\Delta G_{U F}=-R T \log \left(\frac{[U]}{[F]}\right)$$
  对于 F 到 U 的反向变换，我们有：
$$\Delta G_{F U}=-R T \log(\frac{[F]}{[U]}) = -\Delta G_{UF}$$
  如果我们将两种蛋白质W和M视为仅在序列上某一位点的残基不同，那么我们可以很容易地推导出前述方程：
$$\Delta\Delta G_{WM} = R T \log \left(\frac{[U]}{[F]}\right) - R T \log(\frac{[F]}{[U]}) = -\Delta\Delta G_{MW}$$
  实现反对称预测并不容易；Usmanova 等人指出，为了实现完美的反对称性，基于结构的方法应能够从天然结构出发生成变体的最低能量结构，反之亦然。由于工具本身的固有特性，这是一项具有挑战性的任务。因此，在方程中应考虑两个方向上的偏差 $δ_{MW}$ 和 $δ_{WM}$：
$$\Delta\Delta G_{WM} = -\Delta\Delta G_{MW} + δ_{MW} + δ_{WM}$$
  在本文中，我们提出了ACDC-NN，一种用于评估蛋白质变体稳定性变化的新方法，该方法在评分过程中保持了∆∆G测量所具有的反对称物理特性。本研究所提出并探讨的该新工具的主要特点包括：
  * 当前可用实验数据的缺乏，以及应对该问题的相关策略。
  * 通过专门设计的损失函数，在网络结构中引入物理约束，开发出一种满足反对称性要求的方法。
  * 构建一种新颖的深度神经网络架构，能够将成对接触势能和进化信息编码到卷积滤波器中。
  * 考虑蛋白质序列间序列相似性对评估结果的影响，对方法进行合理评估，这一问题在大多数现有方法的评估中往往被忽视。

## 结果
### 利用 DDGun3D 预测学习反对称性
  为了应对实验数据不足的问题，我们采用了迁移学习技术（见第3节）。预训练阶段是在一个从 Ivankov 数据集人工构建的变体子集（我们称之为IvankovDDGun）上进行的。该数据集的∆∆G值使用 DDGun3D 计算得出，DDGun3D是一种主要基于统计势的非训练型预测器。DDGun3D利用序列和结构特征，在保持反对称特性的同时，能够达到与其他最先进的预测方法相当的性能。

  我们使用皮尔逊相关系数（r）和均方根误差（RMSE）来衡量对预测结果的重建能力；∆∆G的反对称性则通过 rd−i（公式(6)）和偏差⟨δ⟩来评估。在 IvankovDDGun 测试集上，ACDC-NN成功复现了DDGun3D的预测结果（r = 0.97–0.98），同时实现了近乎完美的反对称性，rd−i接近−1（表1）。

  结果表明，ACDC-NN仅利用序列和结构信息，即可编码 DDGun3D 所依赖的多种信息，包括 Bastoll 等人和 Skolnick 等人提出的统计势、BLOSUM62 替换矩阵、Kyte–Doolittle 疏水性以及残基溶剂可及性。
### 学习预测实验 ∆∆G 值
  在模拟数据上完成预训练后，ACDC-NN通过10折交叉验证在S2648数据集的实验∆∆G值上进行训练，达到了r = 0.55、RMSE = 1.33的性能。正如预期，其在真实数据上的表现显著低于在模拟数据上的结果。然而，该结果与当前在相同数据集上的最先进方法相当。

  为了评估和比较不同方法在实验数据上的反对称性及预测性能，我们使用了Ssym数据集，该数据集专门构建用于评估方法对自由能的正向和反向变异是否具有同等良好的预测能力。具体而言，在训练集中，我们排除了与Ssym中蛋白质序列相似性超过25%的蛋白质，以确保评估的无偏性（见第3节）。

  表2报告了不同方法在Ssym数据集上对正向及其对应反向变异的预测性能对比，包括皮尔逊相关系数（r）和预测值与实验∆∆G之间的均方根误差（RMSE）。反对称性则通过rd−i和偏差⟨δ⟩进行评估。RMSE和⟨δ⟩的单位为kcal·mol⁻¹。

  表2中的结果表明，在考虑反向变异的相关性时，ACDC-NN的表现优于所有其他预测工具，其性能与用于预训练的DDGun3D方法相近。其他在正向变异上表现较好的预测工具，在反向变异上的性能则明显下降，这表明它们缺乏热力学反对称性，正如Pucci等人先前所指出的那样。

  值得强调的是，在表2列出的方法中，仅有Inps-NoSeqId、ThermoNet、ACDC-NN和ACDC-NN∗是在交叉验证训练过程中排除了序列同源性（即序列相似性低于25%）的条件下进行训练的。此外，ACDC-NN在仅使用单一结构（ACDC-NN）时即表现出优异的反对称性（rd−i = −0.98），而在同时使用正向和反向两种结构时（ACDC-NN∗），其实现了完美的反对称性（rd−i = −1.00）。该模型的两个版本在Ssym数据集的正向和反向变异预测上均优于所有其他方法。
### 在 p53 和肌红蛋白变体上的 ACDC-NN 评估
  我们还在另外两个实验数据集上评估了ACDC-NN，这些数据集包含两种临床相关蛋白质的单点变异：p53转录因子和肌红蛋白。p53数据集由Pires等人构建，包含p53 DNA结合域内的42个变异。肌红蛋白数据集由Kepp整理，共包含134个变异（其中113个变异有多个实验数据）。由于肌红蛋白和p53均存在于S2648训练数据集中，我们采用交叉验证方式（见第3节）进行预测，即在训练时排除与这两种蛋白质序列相似性过高的样本，以确保评估的独立性。

  为了预测反向变异，我们使用 MODELLER 生成了突变体结构，这些结构已公开于我们的在线代码库：https://github.com/compbiomed-unito/acdc-nn 图1展示了ACDC-NN的预测值与实验测定的∆∆G值之间的比较。在两个数据集上获得的性能表现与在Ssym数据集上的结果（表2）一致。与其他现有的深度学习方法Thermonet相比，ACDC-NN表现更优，具体结果见表3和表4。

  图和表略（都是对比数据，直接看文献
### 卷积滤波器分析
  ACDC-NN包含两个独立的卷积层：一个作用于三维残基接触信息（KT），另一个作用于序列邻近残基信息（KS）。图2和图3展示了这两个滤波器的热图，突出显示了从丙氨酸（A）到酪氨酸（Y）的原始氨基酸位置。值得注意的是，KS滤波器作用于包含中心残基（即发生氨基酸替换的位点）的输入，而KT滤波器则作用于仅包含三维空间邻近残基的输入。这一差异导致只有KS滤波器中出现了明显的主对角线。

  需要强调的是，这些滤波器生成了两个20×20的矩阵，这些矩阵可与成对接触势能和进化替代矩阵相关联。具体而言，KS滤波器矩阵与基于进化的替代矩阵和成对接触势能均表现出统计学上显著的相关性，分别与BLOSUM62的相似度达到-0.75，与Simons统计势的相关性达到0.54。相比之下，KT滤波器矩阵仅与接触势能显著相关，特别是与Bastolla-Vendruscolo统计势的相关系数达到0.51（皮尔逊相关系数）。

  这些发现表明，该网络不仅学习到了嵌入在DDGun3D评分中的基于物理和进化的信息，还能够通过将这些信息与其他统计势融合而实现泛化。这说明网络能够从数据中提取出一致的物理关系。
## 材料与方法
### 数据集和交叉验证
  使用了三个先前收集的数据集和一个人工合成的数据集：
  * S2648：包含2,648个经过人工整理的变体，其∆∆G值通过实验测定。
  * Ssym：包含野生型和突变型蛋白质3D结构（通过X射线晶体学解析）的变异数据，共684个变异，其中一半为反向变异。
  * Ivankov2000：包含2,000个单点突变体，具有可用的结构数据，其中1,000个为正向变异，1,000个为反向变异。该数据集未提供实验测得的∆∆G值，因为它专门用于评估现有预测方法的反对称特性。
  * IvankovDDGun：一个由Ivankov2000衍生出的人工数据集，通过对每个序列位点生成所有可能的正向和反向变异，并将相应的DDGun3D预测结果作为∆∆G值。该数据集仅用于神经网络的预训练。

  由于这些数据集还包含相同蛋白质或序列高度相似的蛋白质中的变体，为了在避免过拟合的前提下准确评估方法的预测性能，必须考虑用于训练模型的蛋白质变体与用于测试的蛋白质之间的序列相似性。因此，我们通过生成验证集和测试集，使其所含蛋白质与训练集中蛋白质有足够差异，从而构建交叉验证的折叠。为此，我们使用了blastclust算法，生成序列相似性低于25%的蛋白质聚类（命令：blastclust -i infile.fasta -o out.clusters -p T -L 0.5 -b F -S 25）。(把序列相似性高的分成一组)
#### 序列谱
  对于每个包含至少一个变异的蛋白质，其序列从PDB坐标文件的ATOM字段中提取。使用hhblits工具，将序列与Uniprot数据库（2016年版本）进行多序列比对，参数为默认设置。根据每条比对结果生成一个序列谱，即一个 N × 20 的矩阵，其中 N 为蛋白质的长度，20列分别代表20种氨基酸类型。序列谱中的每个元素 Prof(i, a) 表示在蛋白质序列第 i 个位置上，氨基酸类型 a 出现的频率。
#### 性能评估指标
  为了评估预测性能，计算了预测值与观测值之间的皮尔逊相关系数（用 r 表示）和均方根误差（RMSE）。为了评估∆∆G预测方法的反对称性特性，我们采用了两个评分指标：rd−i 和 ⟨δ⟩。rd−i 是正向变异与其对应反向变异之间的皮尔逊相关系数。
$$r_{d-i} = \frac{Cov(\Delta\Delta G^{dir},\Delta\Delta G^{inv})}{\sigma _{dir}\sigma _{inv}}$$
  其中，Cov 表示协方差，σ 表示标准差。⟨δ⟩ 是衡量预测偏差的平均偏移量：
$$\langle \delta \rangle = \frac{1}{2N} \sum_{i=1}^{N} \left( \Delta\Delta G_i^{\text{dir}} + \Delta\Delta G_i^{\text{inv}} \right)$$
  一个完全反对称的方法应具有等于 -1 的 rd−i 和等于 0 的 ⟨δ⟩。
### 构建 ACDC-NN
  为了满足反对称性特性，我们构建了一种内在具有反对称性的神经网络架构，即“反对称卷积差分拼接神经网络”（Antisymmetric Convolutional Differential Concatenated Neural Network, ACDC-NN）。ACDC-NN 是一种卷积神经网络，它为正向变异（wild-type → mutant）和反向变异（mutant → wild-type）分别提供两个独立的输入。网络通过卷积操作分别处理这两种变异，并将提取到的特征作为两个共享权重的孪生神经网络（siamese neural networks）的输入。由于一个完全反对称的预测器应满足等式 ∆∆GWM = −∆∆GMW，我们设计了一个特定的损失函数，通过以下方程约束神经网络学习这一物理性质：
$$\Delta\Delta G_{WM} + \Delta\Delta G_{MW} = 0$$
  我们通过以下定制的损失函数实现了这些约束：
$$J = log(cosh(D - y)) + abs(S) , with \\
D = (O_{D} - O_I)/2, S = (O_{D} + O_{I})/2$$
  其中，y 是实验测得的 ∆∆G 值，OD 和 OI 分别是差分孪生网络中正向模块和反向模块的输出。使用 log(cosh(x)) 是因为它对异常值的敏感度低于传统的均方误差损失函数。这两个输入各自包含 620 个元素，用于编码突变、序列和结构信息：
  * 变异信息（V）：20个特征（每种氨基酸对应一个），用于编码突变类型。该向量中所有元素初始化为0，仅将野生型氨基酸对应的位置设为−1，突变后氨基酸的位置设为1。该输入对应一个一维矩阵 $V \in R^{20 × l}$
  * 序列信息（S 或 1D输入）：100个特征，表示突变位点周围的序列邻域的蛋白质谱信息。设 i 为序列中的突变位置，我们采用一个大小为5的滑动窗口 $[i - 2, i - 1, i, i + 1, i + 2]$ ，每个位置包含20维的序列谱（profile）信息，因此共 20 × 5 = 100 个元素。该输入对应矩阵 $S \in R^{5×20}$。
  * 结构信息（T 或 3D输入）：500个特征，表示突变位点周围三维结构邻域的蛋白质谱信息。我们选取距离突变位点5Å范围内的所有残基，最多保留25个，并按其与目标氨基酸的距离（Å）由近到远排序，每个残基对应20维序列谱信息，因此共 20 × 25 = 500 个元素，该输入对应矩阵 $T \in R^{25×20}$

  在S（序列信息）和T（结构信息）上分别应用了一个二维卷积层，使用20个滤波器，卷积核大小为(1, 20)，步长为(1, 1)，即Keras风格的参数。该层生成了两个20×20的滤波器矩阵KS和KT，如图2和图3所示。
  $$2D-Conv(S,K_{S}) = S' \quad  where \quad S' \in \mathbb{R}^{5×20}\\
  2D-Conv(T,K_{T}) = T' \quad  where \quad T' \in \mathbb{R}^{25×20}$$
  滤波器矩阵KS和KT在训练阶段被学习。为了使模型对3D邻居的顺序具有不变性，在编码了结构信息的 T' 上应用了2D全局平均池化操作（2D-GAP）。这样可以确保模型对于输入数据中的3D邻居的不同排列具有鲁棒性，通过池化操作来减少过拟合并提取更具代表性的特征。
  $$2D-GAP(T') = T'' \quad where \quad T'' \in \mathbb{R}^{I × 20}$$
  然后，计算突变向量 V 与 T'' 和 S' 之间的点积：
  $$\begin{align*}
D &= T'' \cdot V, \quad \text{where } D \in \mathbb{R}^{1 \times 1} \\
E &= S' \cdot V, \quad \text{where } E \in \mathbb{R}^{5 \times 1}
\end{align*}$$
  经过上述所有操作后，我们得到了六个处理后的特征，这些特征分别针对正向变异及其反向变异进行计算。然后将这些特征与变异向量 V 拼接，并作为输入送入具有共享权重的差分孪生网络（Differential Siamese Networks）。网络的输出通过最后两个 Lambda 层进行组合，分别计算“差值的一半”（difference/2）和平均值（average）。得益于上述损失函数的设计，平均输出被最小化（趋近于零），而差值输出则尽可能接近真实的 ∆∆G 值。ACDC-NN 的整体架构如图4和图5所示。
![](https://cloudflare.remsait.com/img/ADCD-NN202510211747545.png)
#### 预训练
  预训练是在从IvankovDDGun数据集中提取的一组人工生成的∆∆G值上进行的。对于所有正向和反向变异，每个序列位置都被生成，并使用DDGun3D预测的∆∆G值作为输出。ACDC-NN在400,000个模拟变异上进行了训练，这些变异中一半为正向变异，另一半为反向变异。为了寻找最优参数，建立了一个与训练数据集没有交集或序列同源性的验证集（100,000个样本）。最终模型在以相同方式构建的盲测集（100,000个样本）上进行了测试（详见第2节）。我们发现差分网络的最佳配置由分别包含32和16个单元的两个隐藏层组成。关于所有最优参数的完整概览，请参见表5。
#### 使用实验数据进行迁移学习
  在原始网络的基础上，将 ACDC-NN 在包含实验测定 ∆∆G 值的 S2648 数据集上进行重新训练，并对数据进行划分，确保训练集、验证集和测试集之间无序列相似性（即去除同源性）。我们固定了卷积部分的权重，该部分已在预训练中学习到结构和序列特征的紧凑表示；而差分孪生网络部分则进行重新训练。为了增加训练集的规模，我们还将 Ivankov2000 数据集中具有实验测定结构的样本加入训练，并将其 DDGun3D 的预测值作为训练标签（输出目标）。
#### 预测
  ACDC-NN 模型的构建使其可用于两种不同情况下的预测：
  * 当野生型和突变型的三维结构均可用时：将这两种结构分别作为正向和反向输入提供给网络。此时，网络输出的预测结果在结构上天然满足完全反对称性（即 ∆∆GWM = −∆∆GMW），这是由模型架构本身保证的。
  * 当仅存在野生型结构时（这是常见情况）：反向输入是通过将正向输入中的突变编码反转（即将突变从 A→B 改为 B→A）而生成的，但其三维结构仍沿用原始野生型结构（即假设突变不改变整体构象）。在这种情况下，预测结果并非完全反对称，但由于网络结构和训练方式的设计，其反对称性仍然非常接近理想状态，如第2节所示。

## 讨论与结论
  文献中极少有方法能满足热力学所要求的反对称性原则，这要么是由于训练数据集存在偏差，要么是所采用特征本身的固有特性所致。ACDC-NN 的主要创新之处在于，通过设计特定的损失函数，在学习过程中引入了反对称性的物理性质，该损失函数最小化正向与反向预测值之间的绝对差异。

  得益于其网络架构，当野生型和突变型的三维结构（即正向和反向）均可用时，ACDC-NN 能实现完全的反对称性。而当仅有一种结构已知时，ACDC-NN 会构建一个虚拟的反向结构（通过反转突变编码但保持相同构象），仍能保持出色的预测性能和近乎完美的反对称性（见表2）。这种近似处理可能导致轻微的反对称性破坏，这一点在表2中 ACDC-NN*（双结构输入）与 ACDC-NN（单结构输入，反向结构模拟生成）的结果对比中有所体现。

  直到最近，才出现了另一种深度学习方法（ThermoNet），被证明也能够学习到问题的反对称性（见表2）。尽管 ThermoNet 与 ACDC-NN 均基于深度学习架构，但二者在输入数据类型的选择上采用了非常不同的策略。

  另一个重要方面是，ACDC-NN 在评估时使用了与训练数据中蛋白质序列不相似的变异数据，从而更真实地检验模型的泛化能力。在对任何方法进行性能测试时，正确的做法（目前仅有少数方法遵循）是在训练集与测试集之间去除序列相似性，以避免过拟合。我们遵循这一准则，如方法部分所述，将 Ssym 数据集划分为十个子集。如表2所示，在该数据集上，ACDC-NN 始终优于所有现有方法。

  结论：ACDC-NN 是一个用户友好的工具，在保持完美热力学反对称性的同时，表现出与当前最先进方法相当甚至更优的性能。在未来的研究中，该方法可进一步改进，用于预测多位点突变效应，并发展出在缺乏三维结构信息时依然稳健的基于序列的预测模型。