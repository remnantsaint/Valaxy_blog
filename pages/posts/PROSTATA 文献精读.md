---
layout: post
title: PROSTATA 文献精读
date: 2025-10-13 09:33:40
updated: 2025-10-13
time_warning: true 
cover: 
top: 
tags: 
 - ddg
categories: 
 - 生物信息
# author: @Remsait
---
# PROSTATA：一种使用Transformer进行蛋白质稳定性评估的框架
  [PROSTATA: a framework for protein stability assessment  using transformers](https://doi.org/10.1093/bioinformatics/btad671)

  PROSTATA is available at https://github.com/AIRI-Institute/PROSTATA and https://prostata.airi.net.
## 摘要
### 动机
  准确预测单点突变引起的蛋白质稳定性变化是一个极具吸引力但尚未实现的目标。尽管该领域备受关注，但研究者们对Transformer架构的关注却很少，而该架构在机器学习的许多领域中占据主导地位。
### 结果
  在这项工作中，我们提出了PROSTATA，这是一种基于新整理的数据集、以知识迁移方式构建的预测模型。PROSTATA在性能上优于现有的基于神经网络的解决方案。我们证明，其显著的性能提升优势源于模型架构本身以及新训练数据集的高质量。本研究为开发用于蛋白质稳定性评估的新一代轻量级且高精度模型开辟了道路。
## 引言
  单个氨基酸替换对蛋白质稳定性影响的定量预测，仍是一个尚未解决的重大问题。蛋白质的稳定性与其结构、功能及分子进化密切相关。蛋白质稳定性预测是更广泛问题——即预测进化适应性和基因组变异的表型效应——的一部分。

  对突变引起的蛋白质稳定性变化进行准确预测，能够深入揭示蛋白质的折叠机制和功能原理，并在生物产业中具有重要应用价值。蛋白质序列中的氨基酸替换可能具有稳定化、去稳定化或中性效应，具体取决于与野生型蛋白质相比，突变是否更倾向于促进折叠态、去折叠态，或不产生影响（图1）。因此，应用能够隐式捕捉这两种状态变化的机器学习方法显得尤为吸引人。
<img src="https://cloudflare.remsait.com/img/prostata202510131019868.png"  alt="404" title=""  />
<center><div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">
      图 1n
  	</div>
</center>
  近年来，机器学习不可逆转地改变了计算生物学和分子建模的格局。大量用于预测蛋白质稳定性的工具完美地体现了这一变革（Horne 和 Shukla，2022）。我们可以大致将这些工具分为三类：(i) 采用某种经验能量函数的结构建模方法；(ii) 基于支持向量机（SVM）等方法的“简单”机器学习工具；(iii) 深度神经网络，主要是卷积神经网络（CNNs）。第一类包括经典的Rosetta方法（Kellogg 等，2011；Alford 等，2017；Leman 等，2020），以及新近开发的方法，例如PoPMuSiC（Dehouck 等，2011）。Rosetta 是一套大分子建模程序（Kellogg 等，2011），它通过生成并优化突变蛋白及其对应野生型蛋白的三维结构模型，然后计算两者之间的能量差异。Rosetta 采用的能量函数形式为基于物理原理和基于知识的贡献项的线性组合。PoPMuSiC 是一种基于知识的预测工具，它使用一个在大规模实验数据集上训练得到的统计能量函数（Dehouck 等，2011）。
  
  迄今为止，经典的机器学习模型是用于预测蛋白质稳定性的工具中数量最多的一类（Horne 和 Shukla，2022）。Pancotti 等人（2022）对大量现有工具进行了全面比较。例如，DDGun（Montanucci 等，2022）是一种无需训练的方法，它通过线性组合将三个基于进化序列的评分结果整合起来。其基于结构的版本 DDGun3D 在使用 DDGun 的三个评分之外，还引入了通过统计势计算得出的另一项。Bæk 和 Kepp 提出了简单的可解释线性回归模型，其预测准确度与更复杂的预测方法相当（Caldararu 等，2021；Bæk 和 Kepp，2022）。这些回归模型仅使用三个描述符：相对溶剂可及性、体积差异和疏水性差异。PROST（Iqbal 等，2022）是一种基于序列的预测器，用于预测单点氨基酸替换后的蛋白质稳定性。PROST 从诸如 DDGun 和 BoostDDG（Lv 等，2020）等基于序列的预测工具中提取序列特征，同时从 AlphaFold2（Jumper 等，2021）和 iFeature（Chen 等，2018）中提取基于结构的特征，并利用这些提取出的特征训练一个基于 XGBoost 和极限树回归器（extra-trees regressor）的集成模型。

  机器学习模型的性能在很大程度上依赖于训练数据。在蛋白质稳定性研究中使用的大多数数据集都源自ProTherm数据库（Nikam等，2021），这是目前最大的实验突变数据集合。用于模型训练和测试的数据集可以根据实验条件、稳定化与去稳定化突变之间的对称性以及蛋白质序列相似性以不同方式组合。特别是，Pucci等人（2018）强调了训练集对称性的重要性。他们构建了一个名为Ssym的对称测试集，用于比较各种模型在预测稳定化和去稳定化突变方面的性能。结果表明，大多数在非对称数据集上训练的模型对去稳定化突变存在偏差。最近，一项新研究开发了一个超大规模数据集（mega dataset），其中包含了针对长度在37至72个氨基酸之间的迷你蛋白（miniproteins）所进行的约80万次蛋白质稳定性变化的实验测量数据，所有测量均采用高通量方法完成（Tsuboyama等，2023）。该数据集对于训练神经网络模型具有很高的价值（Pak等，2023）。
  
  综上所述，研究人员已开发出多种蛋白质稳定性预测方法。然而，进一步提高预测准确性仍然具有重要意义。与此同时，自Vaswani等人（2017）提出以来，在人工智能多个领域广泛应用的Transformer架构，直到最近才开始被引入蛋白质稳定性预测领域（Born和Manica，2023；Jung等人，2023；Zhou等人，2023）。在本研究中，我们提出了基于Transformer架构的PROSTATA框架，该框架可成功应用于预测单个氨基酸替换所引起的蛋白质稳定性变化。
## 材料与方法
### 外部数据集
  在本研究中，为了将我们的模型与其他神经网络（NN）模型进行比较，我们使用了相应模型原始的训练数据集，前提是这些数据以统一格式易于获取。具体使用的数据集包括：来自STRUM的Q3421（Quan等，2016）、来自ThermoNet的Q3488（Li等，2020）、Dehouck等（2011）提供的广泛使用的S2648训练集，以及来自VariBench的ACDC-NN模型的补充数据（Benevenuta等，2021）。数据集Q3488和Q3421被用于评估非对称训练集对PROSTATA预测性能的影响。为评估模型性能，我们选用了常用的测试集：Ssym（Pucci等，2018）、S669（Pancotti等，2022），以及针对特定蛋白质的肌红蛋白（Myoglobin）和p53测试集（Li等，2020）。
### 数据集构建
  我们基于VariBench数据库（Nair 和 Vihinen，2013）中的相关数据集构建了自有的训练数据集，其中包括一些常用的训练集，如PoPMuSiC-2.0（S2648）（Dehouck 等，2011）、ThermoNet（Q3214）（Li 等，2020）以及VariBench原始数据集（Nair 和 Vihinen，2013）（见补充表S1）。数据经过合并与人工核查。由于我们的模型不将实验条件（如pH和温度）作为输入特征，因此我们根据蛋白质数据库（Protein Data Bank, PDB）的PDB ID、PDB链（chain）以及突变编码（突变位置及突变前后的氨基酸残基）的组合对样本进行聚合，该组合此后统称为“ID”。对于具有相同ID但不同实验条件（pH和温度T）的多个测量值，我们对其ΔΔG值在pH和温度上取平均，并通过五个步骤进行汇总处理。

  * 数据划分。将所有样本根据是否提供实验pH值和温度（T）分为两组：包含pH和T信息的为第一组（Group I），不包含的为第二组（Group II）。
  * 选取核心样本。在第一组中，针对每个唯一的ID，选择其pH最接近标准值（pH = 7）且温度最接近25°C的样本作为“核心样本”。
  * 选取附加样本。从第一组剩余的样本中，对于每一个核心样本，进一步选择与其对应的、满足以下条件的样本：pH在核心pH值±0.5范围内（即 pH = pH_core ± 0.5），且温度在核心温度±10°C范围内（即 T = T_core ± 10°C）。同时，也保留那些ID仅出现在第二组中的样本。
  * 对突变的ΔΔG进行平均。对于所选样本中的每个唯一ID，将其所有符合条件的实验ΔΔG值取算术平均，作为该ID最终的ΔΔG值。
  * 剔除不一致数据。为构建最终数据集，过滤掉存在显著冲突的样本，例如：ΔΔG值符号相反（即同一突变既报告为稳定化又报告为去稳定化），或ΔΔG值的方差超过5 kJ/mol的样本。

  最终，该数据集共包含5196个样本（详见补充表S2）。随后，我们通过整合来自“超大规模数据集”（mega dataset）的样本（Tsuboyama 等，2023）对该数据集进行了扩展，该数据集的处理方法遵循了Pak 等（2023）的方案。为保持数据多样性并防止短蛋白样本过度代表，我们从该超大规模数据集中为每种野生型（WT）蛋白序列选取了70个样本，这一数量与上述自建数据集中每种序列的平均样本数相当。因此，数据集新增了5251个样本。
  
  此外，训练集中为每一个突变都加入了其反向突变（即从突变体恢复为野生型的对应突变），以避免数据集偏向于去稳定化突变，从而确保数据集的平衡性。
  
  “血红蛋白”（Hemoglobin）测试集则是通过从PROSTATA数据集中筛选出在其对应的PDB结构中结合了血红素（HEME，简称HEM）、血红素C（HEME C，简称HEC）或胆绿素IXα（BILIVERDINE IX ALPHA，简称BLA）的样本而构建的。
  
  “寡聚化”（oligomerization）测试集通过从PROSTATA数据集中筛选出以下蛋白质样本构建：其晶体结构处于同源寡聚态（homo-oligomeric state），且超过30%的氨基酸残基与相邻亚基之间的距离在4.5 Å范围内。
  
  “天然迷你蛋白”（mini_natural）和“从头设计的迷你蛋白”（mini_denovo）测试集则通过从超大规模数据集（Tsuboyama等，2023）中提取天然存在和人工设计的迷你蛋白子集构建，这些子集与本研究其他数据集中的蛋白质无同源性（无进化关联）。
  
  为评估PROSTATA框架在对应训练集和测试集上的性能，训练集通过BLAST工具（Camacho等，2009）排除了与测试集存在同源性的序列：若序列一致性（sequence identity）高于30%，且比对E值（E-value）小于0.05，则视为同源序列并被剔除。这一处理旨在避免训练集与测试集之间的数据泄露（data leakage），防止因过拟合导致性能指标虚高，并确保与其他模型的公平比较。
  
  各训练集与测试集的样本数量详见补充表S3。
### 模型架构
  我们将预测突变对蛋白质稳定性的影响视为一个回归任务，输入为两个序列：野生型序列和突变型序列。使用Transformer模型完成此任务分为两个步骤。第一步，利用在一个大规模无标签数据集上预训练好的模型，提取这两个序列的表征（embeddings）。第二步，将野生型和突变型蛋白质的序列表征以某种方式组合成一个统一的表征，再用于预测目标值（ΔΔG）。
  
  模型由两部分组成：
  * Transformer主干网络（backbone）：用于生成野生型和突变型蛋白质序列的嵌入向量（embeddings）。
  * 回归头（regression head）：将两个嵌入向量以多种方式进行组合，并基于组合后的特征预测ΔΔG值（如图2所示）。

  最终的预测结果是通过集成（ensemble）方法得到的：对五个独立训练的模型的预测结果取平均值，作为最终输出。
<img src="https://cloudflare.remsait.com/img/Prostata202510131520138.png"  alt="404" title=""  />
<center><div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">
      图 2，该模型通过拼接、外积或加权组合三种方式融合野生型与突变型蛋白在突变位点的嵌入向量，输入单隐藏层神经网络以预测ΔΔG。
  	</div>
</center>

### 使用Transformer主干网络进行序列嵌入
  目前已有多种在大量无标签蛋白质序列数据上预训练的Transformer模型，例如ProtTrans、ProteinBERT、ESM和ESM-2（Lin等，2023）。在本研究中，我们选择使用ESM-2系列中的一个模型作为嵌入主干网络，因为该系列模型在各种下游任务上的表现优于其他近期的蛋白质语言模型（Lin等，2023）。
  
  ESM-2是一系列不同规模的模型，参数量从8百万到150亿不等，通常更大的模型能够生成更高质量的蛋白质表征。考虑到计算资源的限制，我们在本研究中采用了具有6.5亿参数的ESM-2模型，这是能够在32GB GPU上完成训练的最大可用模型。该模型的隐藏层大小为1280，能够为序列中的每个氨基酸残基生成维度相同的1280维嵌入向量。虽然更大的模型有可能带来更高的预测质量，但其训练和推理时间也会显著增加。在进行序列嵌入时，模型会计算序列中每个氨基酸的表征，同时还会计算特殊标记的表征，即插入在每个序列开头的分类标记（CLS token）以及附加在序列末尾的结束标记（END token）。因此，对于一条长度为N的蛋白质序列，Transformer主干网络的输出是一个大小为(N+2)×1280的向量。
### 回归头
  回归流程的第二步是将野生型（WT）和突变型（MT）的嵌入向量组合成一个联合表征，并将其作为线性回归头的输入。在Transformer模型中，一种常用的方法是使用CLS标记的嵌入向量进行序列分类。在本研究中，我们探索了多种将这些向量融合为单一表征的方式：
  * 将突变位点处的野生型和突变型嵌入向量进行拼接；
  * 计算突变位点处野生型和突变型嵌入向量的外积；
  * 对突变位点处的野生型和突变型嵌入向量进行线性组合；
  * 对CLS标记的嵌入向量进行线性组合；
  * 将CLS标记的嵌入向量与突变位点处的野生型和突变型嵌入向量拼接后，再进行线性组合。
  
  以上各种组合方式如图 2 所示
### 模型训练与集成
  所有模型均使用ADAM优化器进行训练，批量大小（batch size）为1，共训练3个epoch。学习率在前30%的训练样本中从0线性增加到1×10⁻⁵，随后在剩余样本中线性下降至0。Transformer主干网络未被冻结，所有模型参数均以端到端（end-to-end）的方式进行联合训练。超参数的选择参考了Devlin等人（2018）的研究以及作者在文本语言模型和蛋白质语言模型方面的先前经验（Shashkova等，2022）。为了提高训练稳定性并提升预测性能，我们采用了集成学习策略，将前述五种具有不同回归头的模型组合成一个集成模型。最终的预测结果由这五个独立模型的预测值取平均得到。 
### 模型评估
  我们采用皮尔逊相关系数（r）、均方根误差（RMSE）和平均绝对误差（MAE）来评估PROSTATA的性能，并将其与已发表的方法进行比较，这些方法包括：INPS-Seq（Savojardo 等，2021）、ACDC-NN-Seq（Pancotti 等，2021）、DDGun（Montanucci 等，2022）、PremPS（Chen 等，2020）、ThermoNet（Li 等，2020）、Rosetta（Kellogg 等，2011）、DynaMut（Rodrigues 等，2018, 2021）、INPS3D（Savojardo 等，2016）、SDM（Worth 等，2011, Pandurangan 等，2017）、PoPMuSiC（Dehouck 等，2011）、MAESTRO（Laimer 等，2016）和DUET（Pires 等，2014）。这些指标在其他方法的原始论文和综述文章中被广泛使用。因此，为了在原始数据集上将PROSTATA与其他公开可用的工具进行比较，我们依据相应文献中报告的性能指标进行对比（Li 等，2020；Benevenuta 等，2021；Wang 等，2023）。
  
  Ssym和S669数据集上各模型的性能指标取自Pancotti 等（2022）的研究。ACDC-NN/ACDC-NN-Seq的序列谱是通过使用HHblits在UniRef30数据库中搜索同源序列获得的，参数为默认设置（Remmert 等，2011；Mirdita 等，2017）。
  
  ProS-GNN模型使用其在 https://github.com/shuyu-wang/ProS-GNN 提供的代码进行训练。训练集包含Q3488数据集，模型在Ssym和Ssymr数据集上进行测试。模型训练了400个epoch，并以测试集上的皮尔逊相关系数（r）作为早停（early stopping）的依据；此外，对输入的PDB文件中的非突变部分进行了裁剪，仅保留突变位点及其相邻的六个残基。
  
  
  
  后略







