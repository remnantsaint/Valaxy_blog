---
categories: 人工智能
comments: 
cover: 
date: 2024-09-06 10:50:55
image: 
layout: post
tags: 机器学习
time_warning: true
title: 朴素贝叶斯
top: 
---

#### 朴素贝叶斯概述

&emsp; 贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。首先需要介绍贝叶斯分类算法的基础——贝叶斯定理。最后，通过实例来讨论贝叶斯分类中最简单的一种：朴素贝叶斯分类。

#### 贝叶斯理论 & 条件概率

##### 贝叶斯理论

&emsp; 数据集由两类数据组成，数据分布如下所示
![](https://cdn.jsdelivr.net/gh/remnantsaint/hexoImage@main/20240906113001.png)
&emsp; 我们用p1(x,y)来表示数据点(x,y)位于类别1（图中圆点）的概率     
&emsp; 用p2(x,y)来表示数据点(x,y)属于类别2（图中三角）的概率   
&emsp; 可以用下面的规则来判断他的类别

* 如果p1(x,y) > p2(x,y)，那么类别为1
* 如果p1(x,y) < p2(x,y)，那么类别为2
  &emsp; 也就是说，我们会选择高概率对应的类别，这就是贝叶斯决策理论的核心思想，即选择具有最高概率的决策

##### 条件概率

&emsp; 要了解贝叶斯公式：
![](https://cdn.jsdelivr.net/gh/remnantsaint/hexoImage@main/20240906163600.png)
即要求p(c|x)，可以用p(x|c)和p(x)与p(c)来计算。
其中p(x|c)=p(xc)/p(x)

##### 使用条件概率来分类

1. 实际上，贝叶斯决策理论真正需要计算和比较的是p(c1|x,y)和p(c2|x,y)
2. 这些符号的具体意义：给定某个由x,y表示的数据点，那么该数据点来自类别c1的概率是多少？数据点来自类别c2的概率又是多少？注意这些概率与概率p(x,y|c1)不一样，不过可以使用贝叶斯准则来交换概率中条件与结果，也就是以下公式$p(c_i|x,y)=frac{\text{p(x,y|c_i)p(c_j)}}{\text{p(x,y)}}$
3. 使用上面这些定义，可以定义贝叶斯分类准则为：
   &emsp; * 如果 P(c1|x, y) > P(c2|x, y), 那么属于类别 c1;  
   &emsp; * 如果 P(c2|x, y) > P(c1|x, y), 那么属于类别 c2.

##### 使用场景

&emsp; 机器学习的一个重要应用就是文档的自动分类，在文档分类中，整个文档是实例，文档中的某些元素构成特征，把每个词作为一个特征，而每个词的出现或不出现作为该特征的值，这样得到的特征数目就会跟词汇表中的词的数目一样多
&emsp; 朴素贝叶斯是上述贝叶斯分类器的一个扩展，是用于文档分类的常用算法。

#### 朴素贝叶斯原理

##### 工作原理

```
提取所有文档中的词条并进行去重
获取文档的所有类别
计算每个类别中的文档数目
对每篇训练文档: 
    对每个类别: 
        如果词条出现在文档中-->增加该词条的计数值（for循环或者矩阵相加）
        增加所有词条的计数值（此类别下词条总数）
对每个类别: 
    对每个词条: 
        将该词条的数目除以总词条数目得到的条件概率（P(词条|类别)）
返回该文档属于每个类别的条件概率（P(类别|文档的所有词条)）
```

##### 开发流程

```
收集数据: 可以使用任何方法。
准备数据: 需要数值型或者布尔型数据。
分析数据: 有大量特征时，绘制特征作用不大，此时使用直方图效果更好。
训练算法: 计算不同的独立特征的条件概率。
测试算法: 计算错误率。
使用算法: 一个常见的朴素贝叶斯应用是文档分类。可以在任意的分类场景中使用朴素贝叶斯分类器，不一定非要是文本。
```

##### 算法特点

* 优点：在数据较少的情况下仍然有效，可以处理多类别问题
* 缺点：对于输入数据的准备方式较为敏感
* 适用数据类型：标称型数据



#### 参考链接   
&emsp; <https://github.com/remnantsaint/ailearning/blob/master/docs/ml/4.md>