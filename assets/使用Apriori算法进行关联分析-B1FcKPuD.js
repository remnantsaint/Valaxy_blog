import{_ as h}from"./ValaxyMain.vue_vue_type_style_index_0_lang-Lj6vZGyG.js";import{u,c as d,o as g,w as e,r as n,g as a,h as s,f,p}from"./app-D6Hejker.js";import"./YunFooter-BsWuc4uy.js";import"./YunCard.vue_vue_type_script_setup_true_lang-DrznGDEn.js";import"./index-C5okkQwF.js";import"./YunPageHeader.vue_vue_type_script_setup_true_lang-Dma2ZTu7.js";import"./post-C0fFnzag.js";const z={__name:"使用Apriori算法进行关联分析",setup(b,{expose:m}){const t=JSON.parse('{"title":"使用Apriori算法进行关联分析","description":"","frontmatter":{"layout":"post","title":"使用Apriori算法进行关联分析","date":"2024-09-24 09:08:42","cover":null,"top":null,"tags":["机器学习"],"categories":["人工智能","机器学习"]},"headers":[{"level":2,"title":"关联分析","slug":"关联分析","link":"#关联分析","children":[]},{"level":2,"title":"相关术语","slug":"相关术语","link":"#相关术语","children":[]},{"level":2,"title":"Apriori 原理","slug":"apriori-原理","link":"#apriori-原理","children":[{"level":3,"title":"Apriori 算法优缺点","slug":"apriori-算法优缺点","link":"#apriori-算法优缺点","children":[]},{"level":3,"title":"Apriori 算法流程步骤","slug":"apriori-算法流程步骤","link":"#apriori-算法流程步骤","children":[]}]},{"level":2,"title":"Reference","slug":"reference","link":"#reference","children":[]}],"relativePath":"pages/posts/使用Apriori算法进行关联分析.md","path":"/home/runner/work/remnantsaint.github.io/remnantsaint.github.io/pages/posts/使用Apriori算法进行关联分析.md","lastUpdated":1758348498000}'),r=u(),i=t.frontmatter||{};return r.meta.frontmatter=Object.assign(r.meta.frontmatter||{},t.frontmatter||{}),p("pageData",t),p("valaxy:frontmatter",i),globalThis.$frontmatter=i,m({frontmatter:{layout:"post",title:"使用Apriori算法进行关联分析",date:"2024-09-24 09:08:42",cover:null,top:null,tags:["机器学习"],categories:["人工智能","机器学习"]}}),(l,o)=>{const c=h;return g(),d(c,{frontmatter:f(i)},{"main-content-md":e(()=>[...o[0]||(o[0]=[a("h2",{id:"关联分析",tabindex:"-1"},[s("关联分析 "),a("a",{class:"header-anchor",href:"#关联分析","aria-label":'Permalink to "关联分析"'},"​")],-1),a("p",null,"  关联分析是一种在大规模数据集中寻找有趣关系的任务，这些关系可以有以下两种形式",-1),a("ul",null,[a("li",null,"频繁项集：经常出现在一块的物品的集合"),a("li",null,"关联规则：按时两种物品之间存在很强的关系")],-1),a("h2",{id:"相关术语",tabindex:"-1"},[s("相关术语 "),a("a",{class:"header-anchor",href:"#相关术语","aria-label":'Permalink to "相关术语"'},"​")],-1),a("ul",null,[a("li",null,[s("关联分析（关联规则学习）：从大规模数据集中寻找物品间的隐含关系被称作"),a("code",null,"关联分析"),s("或者"),a("code",null,"关联规则学习"),s("，下面是用一个杂货店的例子来说明这两个概念，如下图所示 "),a("img",{src:"https://cdn.jsdelivr.net/gh/remnantsaint/hexoImage@main/202409240920933.png",alt:""})]),a("li",null,"频繁项集：{葡萄酒，尿布，豆奶}就是一个频繁项集的子集"),a("li",null,"关联规则：尿布 -> 葡萄酒 就是一个而关联规则，这意味着顾客如果买了尿布，那么他很可能会买葡萄酒。")],-1),a("blockquote",null,[a("p",null,[a("code",null,"频繁"),s("的定义是什么呢？怎么样才算频繁呢？度量他们的方法有很多种，这里我们来简单的介绍下支持度和可信度。")])],-1),a("ul",null,[a("li",null,"支持度：数据集中包含该项集的记录所占的比例。例如上图中，{豆奶}的支持度为 4/5。{豆奶，尿布}的支持度为 3/5。"),a("li",null,[s("可信度：针对一条诸如{尿布} -> {葡萄酒} 这样的具体关联规则来定义的。这条规则的"),a("code",null,"可信度"),s("被定义为"),a("code",null,"支持度（{尿布，葡萄酒}）/ 支持度（{尿布}）"),s("，从图中可以看出支持度({尿布, 葡萄酒}) = 3/5，支持度({尿布}) = 4/5，所以 {尿布} -> {葡萄酒} 的可信度 = 3/5 / 4/5 = 3/4 = 0.75。")])],-1),a("p",null,[s("  "),a("code",null,"支持度"),s(" 和 "),a("code",null,"可信度"),s(" 是用来量化 "),a("code",null,"关联分析"),s(" 是否成功的一个方法。 假设想找到支持度大于 0.8 的所有项集，应该如何去做呢？ 一个办法是生成一个物品所有可能组合的清单，然后对每一种组合统计它出现的频繁程度，但是当物品成千上万时，上述做法就非常非常慢了。 我们需要详细分析下这种情况并讨论下 Apriori 原理，该原理会减少关联规则学习时所需的计算量。")],-1),a("h2",{id:"apriori-原理",tabindex:"-1"},[s("Apriori 原理 "),a("a",{class:"header-anchor",href:"#apriori-原理","aria-label":'Permalink to "Apriori 原理"'},"​")],-1),a("p",null,[s("  假设我们有四个商品：商品0、商品1、商品2、商品3。那么从左到右所有组合的可能有"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("msup",null,[a("mn",null,"2"),a("mi",null,"N")]),a("mo",null,"−"),a("mn",null,"1"),a("mo",null,"="),a("msup",null,[a("mn",null,"2"),a("mn",null,"4")]),a("mo",null,"−"),a("mn",null,"1"),a("mo",null,"="),a("mn",null,"15")]),a("annotation",{encoding:"application/x-tex"},"2^N - 1 = 2^4 - 1 = 15")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.9247em","vertical-align":"-0.0833em"}}),a("span",{class:"mord"},[a("span",{class:"mord"},"2"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8413em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N")])])])])])])]),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"−"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.6444em"}}),a("span",{class:"mord"},"1"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},"="),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8974em","vertical-align":"-0.0833em"}}),a("span",{class:"mord"},[a("span",{class:"mord"},"2"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8141em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},"4")])])])])])])]),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"−"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.6444em"}}),a("span",{class:"mord"},"1"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},"="),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.6444em"}}),a("span",{class:"mord"},"15")])])]),s("，其中包括{01,02,…012,013…0123}。随着物品的增加，计算次数呈指数增长"),a("br"),s("   为了降低计算次数和时间，研究人员发现了一种所谓的 Apriori 原理，即某个项集是频繁的，那么它所有的子集也是频繁的。例如，如果{0，1}是频繁的，那么{0}，{1}也是频繁的，该原理直观上没有什么帮助，但是反过来看（逆否）就有用了，也就是说如果一个项集是"),a("code",null,"非频繁项集"),s("，那么它所有超集也是非频繁项集。")],-1),a("p",null,"  已知 {2,3} 是 非频繁项集，那么利用上面的知识，我们就可以知道 {0,2,3} {1,2,3} {0,1,2,3} 都是 非频繁的。 也就是说，计算出 {2,3} 的支持度，知道它是 非频繁 的之后，就不需要再计算 {0,2,3} {1,2,3} {0,1,2,3} 的支持度，因为我们知道这些集合不会满足我们的要求。 使用该原理就可以避免项集数目的指数增长，从而在合理的时间内计算出频繁项集。",-1),a("h3",{id:"apriori-算法优缺点",tabindex:"-1"},[s("Apriori 算法优缺点 "),a("a",{class:"header-anchor",href:"#apriori-算法优缺点","aria-label":'Permalink to "Apriori 算法优缺点"'},"​")],-1),a("div",{style:{"max-height":"300px"},class:"language-text vp-adaptive-theme"},[a("button",{title:"Copy Code",class:"copy"}),a("span",{class:"lang"},"text"),a("pre",{class:"shiki shiki-themes github-light github-dark vp-code"},[a("code",{"v-pre":""},[a("span",{class:"line"},[a("span",null,"* 优点: 易编码实现")]),s(`
`),a("span",{class:"line"},[a("span",null,"* 缺点: 在大数据集上可能较慢")]),s(`
`),a("span",{class:"line"},[a("span",null,"* 适用数据类型: 数值型 或者 标称型数据。")])])]),a("button",{class:"collapse"})],-1),a("h3",{id:"apriori-算法流程步骤",tabindex:"-1"},[s("Apriori 算法流程步骤 "),a("a",{class:"header-anchor",href:"#apriori-算法流程步骤","aria-label":'Permalink to "Apriori 算法流程步骤"'},"​")],-1),a("div",{style:{"max-height":"300px"},class:"language-text vp-adaptive-theme"},[a("button",{title:"Copy Code",class:"copy"}),a("span",{class:"lang"},"text"),a("pre",{class:"shiki shiki-themes github-light github-dark vp-code"},[a("code",{"v-pre":""},[a("span",{class:"line"},[a("span",null,"* 收集数据: 使用任意方法。")]),s(`
`),a("span",{class:"line"},[a("span",null,"* 准备数据: 任何数据类型都可以，因为我们只保存集合。")]),s(`
`),a("span",{class:"line"},[a("span",null,"* 分析数据: 使用任意方法。")]),s(`
`),a("span",{class:"line"},[a("span",null,"* 训练数据: 使用Apiori算法来找到频繁项集。")]),s(`
`),a("span",{class:"line"},[a("span",null,"* 测试算法: 不需要测试过程。")]),s(`
`),a("span",{class:"line"},[a("span",null,"* 使用算法: 用于发现频繁项集以及物品之间的关联规则。")])])]),a("button",{class:"collapse"})],-1),a("h2",{id:"reference",tabindex:"-1"},[s("Reference "),a("a",{class:"header-anchor",href:"#reference","aria-label":'Permalink to "Reference"'},"​")],-1),a("p",null,[a("a",{href:"https://github.com/apachecn/ailearning/blob/master/docs/ml/11.md",target:"_blank",rel:"noreferrer"},"https://github.com/apachecn/ailearning/blob/master/docs/ml/11.md")],-1)])]),"main-header":e(()=>[n(l.$slots,"main-header")]),"main-header-after":e(()=>[n(l.$slots,"main-header-after")]),"main-nav":e(()=>[n(l.$slots,"main-nav")]),"main-content":e(()=>[n(l.$slots,"main-content")]),"main-content-after":e(()=>[n(l.$slots,"main-content-after")]),"main-nav-before":e(()=>[n(l.$slots,"main-nav-before")]),"main-nav-after":e(()=>[n(l.$slots,"main-nav-after")]),comment:e(()=>[n(l.$slots,"comment")]),footer:e(()=>[n(l.$slots,"footer")]),aside:e(()=>[n(l.$slots,"aside")]),"aside-custom":e(()=>[n(l.$slots,"aside-custom")]),default:e(()=>[n(l.$slots,"default")]),_:3},8,["frontmatter"])}}};export{z as default};
