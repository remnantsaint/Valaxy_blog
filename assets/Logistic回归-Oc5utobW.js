import{_ as h}from"./ValaxyMain.vue_vue_type_style_index_0_lang-Lj6vZGyG.js";import{u as g,c as u,o as d,w as l,r as n,g as s,h as a,f as y,p}from"./app-D6Hejker.js";import"./YunFooter-BsWuc4uy.js";import"./YunCard.vue_vue_type_script_setup_true_lang-DrznGDEn.js";import"./index-C5okkQwF.js";import"./YunPageHeader.vue_vue_type_script_setup_true_lang-Dma2ZTu7.js";import"./post-C0fFnzag.js";const P={__name:"Logistic回归",setup(v,{expose:c}){const e=JSON.parse('{"title":"Logistic回归","description":"","frontmatter":{"categories":["人工智能","机器学习"],"cover":null,"date":"2024-09-06 10:52:42","image":null,"layout":"post","tags":"机器学习","time_warning":true,"title":"Logistic回归","top":null},"headers":[{"level":2,"title":"Logistic回归概念","slug":"logistic回归概念","link":"#logistic回归概念","children":[{"level":3,"title":"概述","slug":"概述","link":"#概述","children":[]},{"level":3,"title":"Sigmoid函数","slug":"sigmoid函数","link":"#sigmoid函数","children":[]},{"level":3,"title":"基于最优化方法的回归系数确定","slug":"基于最优化方法的回归系数确定","link":"#基于最优化方法的回归系数确定","children":[]},{"level":3,"title":"梯度上升法","slug":"梯度上升法","link":"#梯度上升法","children":[]}]},{"level":2,"title":"Logistic回归原理","slug":"logistic回归原理","link":"#logistic回归原理","children":[{"level":3,"title":"回归工作原理","slug":"回归工作原理","link":"#回归工作原理","children":[]}]},{"level":2,"title":"Todo","slug":"todo","link":"#todo","children":[]},{"level":2,"title":"Reference","slug":"reference","link":"#reference","children":[]}],"relativePath":"pages/posts/Logistic回归.md","path":"/home/runner/work/remnantsaint.github.io/remnantsaint.github.io/pages/posts/Logistic回归.md","lastUpdated":1758348498000}'),i=g(),m=e.frontmatter||{};return i.meta.frontmatter=Object.assign(i.meta.frontmatter||{},e.frontmatter||{}),p("pageData",e),p("valaxy:frontmatter",m),globalThis.$frontmatter=m,c({frontmatter:{categories:["人工智能","机器学习"],cover:null,date:"2024-09-06 10:52:42",image:null,layout:"post",tags:"机器学习",time_warning:!0,title:"Logistic回归",top:null}}),(t,r)=>{const o=h;return d(),u(o,{frontmatter:y(m)},{"main-content-md":l(()=>[...r[0]||(r[0]=[s("h2",{id:"logistic回归概念",tabindex:"-1"},[a("Logistic回归概念 "),s("a",{class:"header-anchor",href:"#logistic回归概念","aria-label":'Permalink to "Logistic回归概念"'},"​")],-1),s("h3",{id:"概述",tabindex:"-1"},[a("概述 "),s("a",{class:"header-anchor",href:"#概述","aria-label":'Permalink to "概述"'},"​")],-1),s("p",null,"  Logistic回归又叫逻辑回归，实际上是用来做分类，主要思想是根据现有数据对分类边界线建立回归公式，以此进行分类",-1),s("h3",{id:"sigmoid函数",tabindex:"-1"},[a("Sigmoid函数 "),s("a",{class:"header-anchor",href:"#sigmoid函数","aria-label":'Permalink to "Sigmoid函数"'},"​")],-1),s("h4",{id:"回归概念",tabindex:"-1"},[a("回归概念 "),s("a",{class:"header-anchor",href:"#回归概念","aria-label":'Permalink to "回归概念"'},"​")],-1),s("p",null,"  假设现在有一些数据点，我们用一条直线对这些点进行拟合（这条直线称为最佳拟合直线），这个拟合过程就叫做回归。进而可以得到对这些点的拟合直线方程，以下是根据这个回归方程如何进行分类。",-1),s("h4",{id:"二值型输出分类函数",tabindex:"-1"},[a("二值型输出分类函数 "),s("a",{class:"header-anchor",href:"#二值型输出分类函数","aria-label":'Permalink to "二值型输出分类函数"'},"​")],-1),s("p",null,[a("  我们需要一个能接受所有输入，然后预测出类别的函数，例如在两个类的情况下，函数只输出0 or 1，这种函数称为"),s("code",null,"海维赛德阶跃函数"),a("，或者直接称为"),s("code",null,"单位阶跃函数"),a("。"),s("br"),a("   然而这个函数的问题在于：该函数在跳跃点上从0瞬间跳跃到1，这个瞬间跳跃过程有时很难处理。而"),s("code",null,"Sigmoid函数"),a("在数学上更容易处理，具体公式如下： "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"σ"),s("mo",{stretchy:"false"},"("),s("mi",null,"z"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("mn",null,"1"),s("mrow",null,[s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"z")])])])])]),s("annotation",{encoding:"application/x-tex"},"\\sigma (z)=\\frac{1}{1+e^{-z} }")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.2484em","vertical-align":"-0.4033em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8451em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7027em"}},[s("span",{style:{top:"-2.786em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.04398em"}},"z")])])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4033em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])]),s("br"),a("   下图给出了Sigmoid函数在不同坐标尺度下的两条曲线图。当x为0时，Sigmoid函数值为 0.5，随着 x 的增大，对应的 Sigmoid 值将逼近于 1；而随着 x 的减小，Sigmoid 的值将逼近于0，如果横坐标刻度足够大，Sigmoid 函数看起来很像一个阶跃函数。 "),s("img",{src:"https://cloudflare.remsait.com/img/%E9%98%B6%E8%B7%83.png",alt:""}),s("br"),a("   为了实现 Logistic 回归分类器，我们可以在每个特征上都乘以一个回归系数，然后把所有结果的值相加，将这个总和带入 Sigmoid 函数中，得到一个范围在 0~1 之间的数值。任何大于 0.5 的数据被分入 1 类，小于 0.5 被分入 0 类，因此 Logistic 回归也是一种概率估计。")],-1),s("h3",{id:"基于最优化方法的回归系数确定",tabindex:"-1"},[a("基于最优化方法的回归系数确定 "),s("a",{class:"header-anchor",href:"#基于最优化方法的回归系数确定","aria-label":'Permalink to "基于最优化方法的回归系数确定"'},"​")],-1),s("p",null,"  将 Sigmoid 函数的输入记为 z ，由下面的公式得到：",-1),s("p",null,[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"z"),s("mo",null,"="),s("msub",null,[s("mi",null,"w"),s("mn",null,"0")]),s("msub",null,[s("mi",null,"x"),s("mn",null,"0")]),s("mo",null,"+"),s("msub",null,[s("mi",null,"w"),s("mn",null,"1")]),s("msub",null,[s("mi",null,"x"),s("mn",null,"1")]),s("mo",null,"+"),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mo",null,"+"),s("msub",null,[s("mi",null,"w"),s("mi",null,"n")]),s("msub",null,[s("mi",null,"x"),s("mi",null,"n")])]),s("annotation",{encoding:"application/x-tex"},"z = w_{0}x_{0} + w_{1}x_{1} + ......+w_{n}x_n ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"0")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"0")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord"},"......"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"n")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])])])],-1),s("p",null,[a("  如果采用向量的写法，上述公式可以写成"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"z"),s("mo",null,"="),s("msup",null,[s("mi",null,"w"),s("mi",null,"T")]),s("mi",null,"x")]),s("annotation",{encoding:"application/x-tex"},"z=w^{T}x")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8413em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8413em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"T")])])])])])])])]),s("span",{class:"mord mathnormal"},"x")])])]),a("，它表示将这两个数值向量对应的元素相乘然后全部加起来得到 z 值。其中向量 x 是分类器的输入数据，向量 w 是我们要找的最佳参数（系数），从而使得分类器尽可能地精确。为了寻找该最佳参数，需要用到最优化理论的一些知识，这里我们使用——梯度上升法（Gradient Ascent）。")],-1),s("h3",{id:"梯度上升法",tabindex:"-1"},[a("梯度上升法 "),s("a",{class:"header-anchor",href:"#梯度上升法","aria-label":'Permalink to "梯度上升法"'},"​")],-1),s("h4",{id:"梯度的介绍",tabindex:"-1"},[a("梯度的介绍 "),s("a",{class:"header-anchor",href:"#梯度的介绍","aria-label":'Permalink to "梯度的介绍"'},"​")],-1),s("ul",null,[s("li",null,"向量 = 值 + 方向"),s("li",null,"梯度 = 向量"),s("li",null,"梯度 = 梯度值 + 梯度方向")],-1),s("h4",{id:"梯度上升法的思想",tabindex:"-1"},[a("梯度上升法的思想 "),s("a",{class:"header-anchor",href:"#梯度上升法的思想","aria-label":'Permalink to "梯度上升法的思想"'},"​")],-1),s("p",null,"  要找到某函数的最大值，最好的方法是沿着该函数的梯度方向探寻。将梯度记为 ▽ ，则函数 f(x,y) 的梯度由下式表示：",-1),s("p",null,[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∇"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{separator:"true"},","),s("mi",null,"y"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mrow",null,[s("mo",{fence:"true"},"["),s("mtable",{rowspacing:"0.16em",columnalign:"center",columnspacing:"1em"},[s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mfrac",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{separator:"true"},","),s("mi",null,"y"),s("mo",{stretchy:"false"},")")]),s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"x")])])])])]),s("mtr",null,[s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"false"},[s("mfrac",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{separator:"true"},","),s("mi",null,"y"),s("mo",{stretchy:"false"},")")]),s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"y")])])])])])]),s("mo",{fence:"true"},"]")])]),s("annotation",{encoding:"application/x-tex"},"\\nabla f(x,y) = \\begin{bmatrix}\\frac{\\partial f(x,y)}{\\partial x} \\\\ \\frac{\\partial f(x,y)}{\\partial y} \\end{bmatrix}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"∇"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"3em","vertical-align":"-1.25em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},"[")]),s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-c"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.6806em"}},[s("span",{style:{top:"-3.6806em"}},[s("span",{class:"pstrut",style:{height:"3.01em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.01em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal mtight"},"x")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.485em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mclose mtight"},")")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.345em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])]),s("span",{style:{top:"-2.3106em"}},[s("span",{class:"pstrut",style:{height:"3.01em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.01em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"y")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.485em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mclose mtight"},")")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4811em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.1806em"}},[s("span")])])])])])]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},"]")])])])])])])],-1),s("p",null,[a("  这个梯度意味着要沿 x 的方向移动"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mfrac",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{separator:"true"},","),s("mi",null,"y"),s("mo",{stretchy:"false"},")")]),s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"x")])])]),s("annotation",{encoding:"application/x-tex"},"\\frac{\\partial f(x,y)}{\\partial x}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.355em","vertical-align":"-0.345em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.01em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal mtight"},"x")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.485em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mclose mtight"},")")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.345em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])]),a("，沿 y 的方向移动"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mfrac",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{separator:"true"},","),s("mi",null,"y"),s("mo",{stretchy:"false"},")")]),s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"y")])])]),s("annotation",{encoding:"application/x-tex"},"\\frac{\\partial f(x,y)}{\\partial y}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.4911em","vertical-align":"-0.4811em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.01em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"y")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.485em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mclose mtight"},")")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4811em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])]),a("。其中，函数 f(x,y) 必须要在待计算的点上由定义并且可微。"),s("br"),s("img",{src:"https://cloudflare.remsait.com/img/tidushangsheng.png",alt:""}),a("   梯度上升算法到每个点后都会重新估计移动的方向。从 P0 开始，计算完该点的梯度，函数就根据梯度移动到下一点 P1 。在 P1 点，梯度再次被计算，并沿着新的梯度方向移动到 P2 ，如此循环迭代，直到满足停止条件。迭代过程中，梯度算子总是保证我们能选取到最佳的移动方向，即函数值增长最快的方向。这里所说的是移动方向，未提到移动量的大小，该量值称为步长，记作 α。用向量来表示的话，梯度上升算法的迭代公式如下"),s("br"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"w"),s("mo",null,":"),s("mo",null,"="),s("mi",null,"w"),s("mo",null,"+"),s("mi",null,"α"),s("mi",{mathvariant:"normal"},"∇"),s("mi",null,"w"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"w"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"w := w + α\\nabla wf(w)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},":="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"mord"},"∇"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mclose"},")")])])]),s("br"),a("   该公式将一直被迭代执行，直到达到某个停止条件为止，比如迭代次数达到某个指定值或者算法达到某个可以允许的误差范围。"),s("br"),a(" 相关概念：")],-1),s("div",{style:{"max-height":"300px"},class:"language-text vp-adaptive-theme"},[s("button",{title:"Copy Code",class:"copy"}),s("span",{class:"lang"},"text"),s("pre",{class:"shiki shiki-themes github-light github-dark vp-code"},[s("code",{"v-pre":""},[s("span",{class:"line"},[s("span",null,"例如: y = w0 + w1x1 + w2x2 + ... + wnxn")]),a(`
`),s("span",{class:"line"},[s("span",null,"梯度: 参考上图的例子，二维图像，x方向代表第一个系数，也就是 w1，y方向代表第二个系数也就是 w2，这样的向量就是梯度。")]),a(`
`),s("span",{class:"line"},[s("span",null,"α: 上面的梯度算法的迭代公式中的阿尔法，这个代表的是移动步长（step length）。移动步长会影响最终结果的拟合程度，最好的方法就是随着迭代次数更改移动步长。")]),a(`
`),s("span",{class:"line"},[s("span",null,"步长通俗的理解，100米，如果我一步走10米，我需要走10步；如果一步走20米，我只需要走5步。这里的一步走多少米就是步长的意思。")]),a(`
`),s("span",{class:"line"},[s("span",null,"▽f(w): 代表沿着梯度变化的方向。")])])]),s("button",{class:"collapse"})],-1),s("blockquote",null,[s("p",null,[a("如果目标函数是损失函数，就叫梯度下降算法。如果目标函数是似然函数，就叫梯度上升算法。 对应的公式可以写成"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"w"),s("mo",null,":"),s("mo",null,"="),s("mi",null,"w"),s("mo",null,"−"),s("mi",null,"α"),s("mi",{mathvariant:"normal"},"∇"),s("mi",null,"w"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"w"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"w := w - α\\nabla wf(w)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},":="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"mord"},"∇"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mclose"},")")])])])])],-1),s("h4",{id:"局部最优现象-local-optima",tabindex:"-1"},[a("局部最优现象 (Local Optima) "),s("a",{class:"header-anchor",href:"#局部最优现象-local-optima","aria-label":'Permalink to "局部最优现象 (Local Optima)"'},"​")],-1),s("p",null,"  我们想最小化损失函数，就是让损失函数的值尽可能的低，然是梯度下降的最终点并非是全局最小点，也可能是一个局部最小点。   所以这个算法将会在很大的程度上被初始点的选择影响而陷入局部最小点。",-1),s("h2",{id:"logistic回归原理",tabindex:"-1"},[a("Logistic回归原理 "),s("a",{class:"header-anchor",href:"#logistic回归原理","aria-label":'Permalink to "Logistic回归原理"'},"​")],-1),s("h3",{id:"回归工作原理",tabindex:"-1"},[a("回归工作原理 "),s("a",{class:"header-anchor",href:"#回归工作原理","aria-label":'Permalink to "回归工作原理"'},"​")],-1),s("div",{style:{"max-height":"300px"},class:"language-text vp-adaptive-theme"},[s("button",{title:"Copy Code",class:"copy"}),s("span",{class:"lang"},"text"),s("pre",{class:"shiki shiki-themes github-light github-dark vp-code"},[s("code",{"v-pre":""},[s("span",{class:"line"},[s("span",null,"每个回归系数初始化为 1")]),a(`
`),s("span",{class:"line"},[s("span",null,"重复 R 次:")]),a(`
`),s("span",{class:"line"},[s("span",null,"    计算整个数据集的梯度")]),a(`
`),s("span",{class:"line"},[s("span",null,"    使用 步长 x 梯度 更新回归系数的向量")]),a(`
`),s("span",{class:"line"},[s("span",null,"返回回归系数")])])]),s("button",{class:"collapse"})],-1),s("h4",{id:"回归开发流程",tabindex:"-1"},[a("回归开发流程 "),s("a",{class:"header-anchor",href:"#回归开发流程","aria-label":'Permalink to "回归开发流程"'},"​")],-1),s("div",{style:{"max-height":"300px"},class:"language-text vp-adaptive-theme"},[s("button",{title:"Copy Code",class:"copy"}),s("span",{class:"lang"},"text"),s("pre",{class:"shiki shiki-themes github-light github-dark vp-code"},[s("code",{"v-pre":""},[s("span",{class:"line"},[s("span",null,"收集数据: 采用任意方法收集数据")]),a(`
`),s("span",{class:"line"},[s("span",null,"准备数据: 由于需要进行距离计算，因此要求数据类型为数值型。另外，结构化数据格式则最佳。")]),a(`
`),s("span",{class:"line"},[s("span",null,"分析数据: 采用任意方法对数据进行分析。")]),a(`
`),s("span",{class:"line"},[s("span",null,"训练算法: 大部分时间将用于训练，训练的目的是为了找到最佳的分类回归系数。")]),a(`
`),s("span",{class:"line"},[s("span",null,"测试算法: 一旦训练步骤完成，分类将会很快。")]),a(`
`),s("span",{class:"line"},[s("span",null,"使用算法: 首先，我们需要输入一些数据，并将其转换成对应的结构化数值；接着，基于训练好的回归系数就可以对这些数值进行简单的回归计算，判定它们属于哪个类别；在这之后，我们就可以在输出的类别上做一些其他分析工作。")])])]),s("button",{class:"collapse"})],-1),s("h4",{id:"logistic回归算法特点",tabindex:"-1"},[a("Logistic回归算法特点 "),s("a",{class:"header-anchor",href:"#logistic回归算法特点","aria-label":'Permalink to "Logistic回归算法特点"'},"​")],-1),s("ul",null,[s("li",null,"优点：计算代价不高，易于理解和实现"),s("li",null,"缺点：容易欠拟合，分类精度可能不高"),s("li",null,"适用数据类型：数值型和标称型数据")],-1),s("h2",{id:"todo",tabindex:"-1"},[a("Todo "),s("a",{class:"header-anchor",href:"#todo","aria-label":'Permalink to "Todo"'},"​")],-1),s("p",null,"项目实战",-1),s("h2",{id:"reference",tabindex:"-1"},[a("Reference "),s("a",{class:"header-anchor",href:"#reference","aria-label":'Permalink to "Reference"'},"​")],-1),s("p",null,[s("a",{href:"https://github.com/remnantsaint/ailearning/blob/master/docs/ml/5.md",target:"_blank",rel:"noreferrer"},"https://github.com/remnantsaint/ailearning/blob/master/docs/ml/5.md")],-1)])]),"main-header":l(()=>[n(t.$slots,"main-header")]),"main-header-after":l(()=>[n(t.$slots,"main-header-after")]),"main-nav":l(()=>[n(t.$slots,"main-nav")]),"main-content":l(()=>[n(t.$slots,"main-content")]),"main-content-after":l(()=>[n(t.$slots,"main-content-after")]),"main-nav-before":l(()=>[n(t.$slots,"main-nav-before")]),"main-nav-after":l(()=>[n(t.$slots,"main-nav-after")]),comment:l(()=>[n(t.$slots,"comment")]),footer:l(()=>[n(t.$slots,"footer")]),aside:l(()=>[n(t.$slots,"aside")]),"aside-custom":l(()=>[n(t.$slots,"aside-custom")]),default:l(()=>[n(t.$slots,"default")]),_:3},8,["frontmatter"])}}};export{P as default};
