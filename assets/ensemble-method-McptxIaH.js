import{_ as c}from"./ValaxyMain.vue_vue_type_style_index_0_lang-Lj6vZGyG.js";import{u as b,c as g,o as m,w as e,r as t,g as l,h as a,f as p,p as d}from"./app-D6Hejker.js";import"./YunFooter-BsWuc4uy.js";import"./YunCard.vue_vue_type_script_setup_true_lang-DrznGDEn.js";import"./index-C5okkQwF.js";import"./YunPageHeader.vue_vue_type_script_setup_true_lang-Dma2ZTu7.js";import"./post-C0fFnzag.js";const C={__name:"ensemble-method",setup(f,{expose:u}){const s=JSON.parse('{"title":"集成方法","description":"","frontmatter":{"layout":"post","title":"集成方法","date":"2024-09-18 10:43:28","cover":null,"top":null,"tags":"机器学习","categories":["人工智能","机器学习"]},"headers":[{"level":2,"title":"集成方法 概述","slug":"集成方法-概述","link":"#集成方法-概述","children":[]},{"level":2,"title":"集成方法 场景","slug":"集成方法-场景","link":"#集成方法-场景","children":[{"level":3,"title":"bagging 和 boosting 的区别","slug":"bagging-和-boosting-的区别","link":"#bagging-和-boosting-的区别","children":[]}]},{"level":2,"title":"随机森林","slug":"随机森林","link":"#随机森林","children":[{"level":3,"title":"随机森林 概述","slug":"随机森林-概述","link":"#随机森林-概述","children":[]},{"level":3,"title":"随机森林 原理","slug":"随机森林-原理","link":"#随机森林-原理","children":[]},{"level":3,"title":"随机森林 开发流程","slug":"随机森林-开发流程","link":"#随机森林-开发流程","children":[]},{"level":3,"title":"随机森林 算法特点","slug":"随机森林-算法特点","link":"#随机森林-算法特点","children":[]}]},{"level":2,"title":"AdaBoost","slug":"adaboost","link":"#adaboost","children":[{"level":3,"title":"AdaBoost 概述","slug":"adaboost-概述","link":"#adaboost-概述","children":[]},{"level":3,"title":"AdaBoost 原理","slug":"adaboost-原理","link":"#adaboost-原理","children":[]},{"level":3,"title":"AdaBoost 开发流程","slug":"adaboost-开发流程","link":"#adaboost-开发流程","children":[]},{"level":3,"title":"AdaBoost 算法特点","slug":"adaboost-算法特点","link":"#adaboost-算法特点","children":[]}]},{"level":2,"title":"参考链接","slug":"参考链接","link":"#参考链接","children":[]}],"relativePath":"pages/posts/ensemble-method.md","path":"/home/runner/work/remnantsaint.github.io/remnantsaint.github.io/pages/posts/ensemble-method.md","lastUpdated":1758348498000}'),i=b(),o=s.frontmatter||{};return i.meta.frontmatter=Object.assign(i.meta.frontmatter||{},s.frontmatter||{}),d("pageData",s),d("valaxy:frontmatter",o),globalThis.$frontmatter=o,u({frontmatter:{layout:"post",title:"集成方法",date:"2024-09-18 10:43:28",cover:null,top:null,tags:"机器学习",categories:["人工智能","机器学习"]}}),(n,r)=>{const h=c;return m(),g(h,{frontmatter:p(o)},{"main-content-md":e(()=>[...r[0]||(r[0]=[l("h2",{id:"集成方法-概述",tabindex:"-1"},[a("集成方法 概述 "),l("a",{class:"header-anchor",href:"#集成方法-概述","aria-label":'Permalink to "集成方法 概述"'},"​")],-1),l("ul",null,[l("li",null,"概念：集成方法是对其他算法进行组合的一种形式"),l("li",null,"通俗来说，当做重要决定时，大家可能都会考虑多个专家而不是一个人的意见，也就是说多方面考虑。"),l("li",null,[a("集成方法： "),l("ul",null,[l("li",null,"投票选举法：基于数据随机重抽样分类器构造的方法"),l("li",null,"再学习：是基于所有分类器的加权求和的方法")])])],-1),l("h2",{id:"集成方法-场景",tabindex:"-1"},[a("集成方法 场景 "),l("a",{class:"header-anchor",href:"#集成方法-场景","aria-label":'Permalink to "集成方法 场景"'},"​")],-1),l("ol",null,[l("li",null,[l("p",null,"目前 bagging 方法最流行的版本是：随机森林（random forest）"),l("ul",null,[l("li",null,"在所有算法中选择综合得分最高的那个")])]),l("li",null,[l("p",null,"目前 boosting 方法最流行的版本是：AdaBoost"),l("ul",null,[l("li",null,"通过再学习方法，一个一个来学习特征，最后选择轮到都做到的那个。")])])],-1),l("h3",{id:"bagging-和-boosting-的区别",tabindex:"-1"},[a("bagging 和 boosting 的区别 "),l("a",{class:"header-anchor",href:"#bagging-和-boosting-的区别","aria-label":'Permalink to "bagging 和 boosting 的区别"'},"​")],-1),l("ol",null,[l("li",null,"bagging 是一种和 boosting 很类似的技术，所使用的多个分类器的类型（数据量和特征量）都是一致的。"),l("li",null,"bagging 是由不同的分类器（1.数据随机化 2.特征随机化）训练，综合得出的出现最多分类结果；boosting 是通过调整已有分类器错分的那些数据来获得新的分类器，得出目前最优的结果。"),l("li",null,"bagging 中的分类器权重是相等的；而 boosting 中的分类器加权求和，所以权重并不相等，每个权重代表的是其对应分类器在上一轮迭代中的成功度。")],-1),l("h2",{id:"随机森林",tabindex:"-1"},[a("随机森林 "),l("a",{class:"header-anchor",href:"#随机森林","aria-label":'Permalink to "随机森林"'},"​")],-1),l("h3",{id:"随机森林-概述",tabindex:"-1"},[a("随机森林 概述 "),l("a",{class:"header-anchor",href:"#随机森林-概述","aria-label":'Permalink to "随机森林 概述"'},"​")],-1),l("ul",null,[l("li",null,"随机森林指的是利用多棵树对样本进行训练并且预测的一种分类器"),l("li",null,"决策树相当于一个大师，通过自己在数据集中学到的知识用于新数据的分类，希望构建多个分类器，来将最终分类效果超过单个分类的效果。")],-1),l("h3",{id:"随机森林-原理",tabindex:"-1"},[a("随机森林 原理 "),l("a",{class:"header-anchor",href:"#随机森林-原理","aria-label":'Permalink to "随机森林 原理"'},"​")],-1),l("p",null,"构建随机森林有两方面：",-1),l("ol",null,[l("li",null,"数据的随机性化"),l("li",null,"待选特征的随机化 使得随机森林中的决策树都能够彼此不同，提升系统的多样性，从而提升分类性能。")],-1),l("blockquote",null,[l("p",null,"数据的随机化：使得随机森林中的决策树更普遍化一点，适合更多场景")],-1),l("ol",null,[l("li",null,"采用有放回的抽样方式构造子数据集，保证不同子集之间的数量级一样（不同子集 / 同一子集 之间的元素可以重复）"),l("li",null,"利用子数据集来构建决策树，将这个数据放到每个子决策树中，每个子决策树输出一个结果。"),l("li",null,"然后统计子决策树的投票结果，得到最终的分类 就是 随机森林的输出结果"),l("li",null,"假设随机森林中有 3 棵子决策树，2 棵子树的分类结果是 A 类，1 棵子树的分类结果是 B 类，那么随机森林的分类结果就是 A 类。")],-1),l("blockquote",null,[l("p",null,"待选特征的随机化")],-1),l("ol",null,[l("li",null,"子树从所有的待选特征中随机选取一定的特征"),l("li",null,"在这些选取的特征中选取最优的特征")],-1),l("h3",{id:"随机森林-开发流程",tabindex:"-1"},[a("随机森林 开发流程 "),l("a",{class:"header-anchor",href:"#随机森林-开发流程","aria-label":'Permalink to "随机森林 开发流程"'},"​")],-1),l("div",{style:{"max-height":"300px"},class:"language-text vp-adaptive-theme"},[l("button",{title:"Copy Code",class:"copy"}),l("span",{class:"lang"},"text"),l("pre",{class:"shiki shiki-themes github-light github-dark vp-code"},[l("code",{"v-pre":""},[l("span",{class:"line"},[l("span",null,"收集数据: 任何方法")]),a(`
`),l("span",{class:"line"},[l("span",null,"准备数据: 转换样本集")]),a(`
`),l("span",{class:"line"},[l("span",null,"分析数据: 任何方法")]),a(`
`),l("span",{class:"line"},[l("span",null,"训练算法: 通过数据随机化和特征随机化，进行多实例的分类评估")]),a(`
`),l("span",{class:"line"},[l("span",null,"测试算法: 计算错误率")]),a(`
`),l("span",{class:"line"},[l("span",null,"使用算法: 输入样本数据，然后运行 随机森林 算法判断输入数据分类属于哪个分类，最后对计算出的分类执行后续处理")])])]),l("button",{class:"collapse"})],-1),l("h3",{id:"随机森林-算法特点",tabindex:"-1"},[a("随机森林 算法特点 "),l("a",{class:"header-anchor",href:"#随机森林-算法特点","aria-label":'Permalink to "随机森林 算法特点"'},"​")],-1),l("ul",null,[l("li",null,"优点: 几乎不需要输入准备、可实现隐式特征选择、训练速度非常快、其他模型很难超越、很难建立一个糟糕的随机森林模型、大量优秀、免费以及开源的实现。"),l("li",null,"缺点: 劣势在于模型大小、是个很难去解释的黑盒子。"),l("li",null,"适用数据范围: 数值型和标称型")],-1),l("h2",{id:"adaboost",tabindex:"-1"},[a("AdaBoost "),l("a",{class:"header-anchor",href:"#adaboost","aria-label":'Permalink to "AdaBoost"'},"​")],-1),l("h3",{id:"adaboost-概述",tabindex:"-1"},[a("AdaBoost 概述 "),l("a",{class:"header-anchor",href:"#adaboost-概述","aria-label":'Permalink to "AdaBoost 概述"'},"​")],-1),l("h3",{id:"adaboost-原理",tabindex:"-1"},[a("AdaBoost 原理 "),l("a",{class:"header-anchor",href:"#adaboost-原理","aria-label":'Permalink to "AdaBoost 原理"'},"​")],-1),l("figure",null,[l("img",{src:"https://cloudflare.remsait.com/img/AdaBoost.png",alt:"",loading:"lazy",decoding:"async"})],-1),l("h3",{id:"adaboost-开发流程",tabindex:"-1"},[a("AdaBoost 开发流程 "),l("a",{class:"header-anchor",href:"#adaboost-开发流程","aria-label":'Permalink to "AdaBoost 开发流程"'},"​")],-1),l("div",{style:{"max-height":"300px"},class:"language-text vp-adaptive-theme"},[l("button",{title:"Copy Code",class:"copy"}),l("span",{class:"lang"},"text"),l("pre",{class:"shiki shiki-themes github-light github-dark vp-code"},[l("code",{"v-pre":""},[l("span",{class:"line"},[l("span",null,"收集数据: 可以使用任意方法")]),a(`
`),l("span",{class:"line"},[l("span",null,"准备数据: 依赖于所使用的弱分类器类型，本章使用的是单层决策树，这种分类器可以处理任何数据类型。    ")]),a(`
`),l("span",{class:"line"},[l("span",null,"    当然也可以使用任意分类器作为弱分类器，第2章到第6章中的任一分类器都可以充当弱分类器。")]),a(`
`),l("span",{class:"line"},[l("span",null,"    作为弱分类器，简单分类器的效果更好。")]),a(`
`),l("span",{class:"line"},[l("span",null,"分析数据: 可以使用任意方法。")]),a(`
`),l("span",{class:"line"},[l("span",null,"训练算法: AdaBoost 的大部分时间都用在训练上，分类器将多次在同一数据集上训练弱分类器。")]),a(`
`),l("span",{class:"line"},[l("span",null,"测试算法: 计算分类的错误率。")]),a(`
`),l("span",{class:"line"},[l("span",null,"使用算法: 和SVM一样，AdaBoost 预测两个类别中的一个。如果想把它应用到多个类别的场景，那么就要像多类 SVM 中的做法一样对 AdaBoost 进行修改。")])])]),l("button",{class:"collapse"})],-1),l("h3",{id:"adaboost-算法特点",tabindex:"-1"},[a("AdaBoost 算法特点 "),l("a",{class:"header-anchor",href:"#adaboost-算法特点","aria-label":'Permalink to "AdaBoost 算法特点"'},"​")],-1),l("ul",null,[l("li",null,"优点: 泛化（由具体的、个别的扩大为一般的）错误率低，易编码，可以应用在大部分分类器上，无参数调节。"),l("li",null,"缺点: 对离群点敏感。"),l("li",null,"适用数据类型: 数值型和标称型数据。")],-1),l("h2",{id:"参考链接",tabindex:"-1"},[a("参考链接 "),l("a",{class:"header-anchor",href:"#参考链接","aria-label":'Permalink to "参考链接"'},"​")],-1),l("p",null,[l("a",{href:"https://github.com/apachecn/ailearning/blob/master/docs/ml/7.md",target:"_blank",rel:"noreferrer"},"https://github.com/apachecn/ailearning/blob/master/docs/ml/7.md")],-1)])]),"main-header":e(()=>[t(n.$slots,"main-header")]),"main-header-after":e(()=>[t(n.$slots,"main-header-after")]),"main-nav":e(()=>[t(n.$slots,"main-nav")]),"main-content":e(()=>[t(n.$slots,"main-content")]),"main-content-after":e(()=>[t(n.$slots,"main-content-after")]),"main-nav-before":e(()=>[t(n.$slots,"main-nav-before")]),"main-nav-after":e(()=>[t(n.$slots,"main-nav-after")]),comment:e(()=>[t(n.$slots,"comment")]),footer:e(()=>[t(n.$slots,"footer")]),aside:e(()=>[t(n.$slots,"aside")]),"aside-custom":e(()=>[t(n.$slots,"aside-custom")]),default:e(()=>[t(n.$slots,"default")]),_:3},8,["frontmatter"])}}};export{C as default};
