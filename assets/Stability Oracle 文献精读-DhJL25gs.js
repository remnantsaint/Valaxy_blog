import{_ as h}from"./ValaxyMain.vue_vue_type_style_index_0_lang-B5W-C4hy.js";import{u,c as g,o as d,w as l,r as n,g as a,h as s,f as y,p as c}from"./app-CiB7UBw_.js";import"./YunFooter-tBh2ornf.js";import"./YunCard.vue_vue_type_script_setup_true_lang-Bt2wnHI3.js";import"./index-C5okkQwF.js";import"./YunPageHeader.vue_vue_type_script_setup_true_lang-CE6MNawq.js";import"./post-Czwbn2Xh.js";const f={__name:"Stability Oracle 文献精读",setup(b,{expose:o}){const e=JSON.parse('{"title":"Stability Oracle 文献精读","description":"","frontmatter":{"layout":"post","title":"Stability Oracle 文献精读","date":"2025-10-29 20:19:24","updated":"2025-10-29","time_warning":true,"cover":null,"top":null,"tags":["ddg"],"categories":["生物信息"]},"headers":[{"level":2,"title":"摘要","slug":"摘要","link":"#摘要","children":[]},{"level":2,"title":"引言","slug":"引言","link":"#引言","children":[]},{"level":2,"title":"结果","slug":"结果","link":"#结果","children":[{"level":3,"title":"设计用于基于结构的蛋白质工程的图-Transformer框架","slug":"设计用于基于结构的蛋白质工程的图-transformer框架","link":"#设计用于基于结构的蛋白质工程的图-transformer框架","children":[]},{"level":3,"title":"训练 Stability Oracle 以泛化至蛋白质化学的各个层面","slug":"训练-stability-oracle-以泛化至蛋白质化学的各个层面","link":"#训练-stability-oracle-以泛化至蛋白质化学的各个层面","children":[]},{"level":3,"title":"评估Stability Oracle识别稳定化突变的能力","slug":"评估stability-oracle识别稳定化突变的能力","link":"#评估stability-oracle识别稳定化突变的能力","children":[]},{"level":3,"title":"比较基于序列与结构的微调稳定性预测模型","slug":"比较基于序列与结构的微调稳定性预测模型","link":"#比较基于序列与结构的微调稳定性预测模型","children":[]}]},{"level":2,"title":"讨论","slug":"讨论","link":"#讨论","children":[]},{"level":2,"title":"方法","slug":"方法","link":"#方法","children":[{"level":3,"title":"模型架构","slug":"模型架构","link":"#模型架构","children":[]},{"level":3,"title":"MutComputeXGT：用于氨基酸概率预测的自监督图注意力网络模型","slug":"mutcomputexgt-用于氨基酸概率预测的自监督图注意力网络模型","link":"#mutcomputexgt-用于氨基酸概率预测的自监督图注意力网络模型","children":[]},{"level":3,"title":"Stability Oracle：用于ΔΔG预测的图注意力网络微调框架","slug":"stability-oracle-用于δδg预测的图注意力网络微调框架","link":"#stability-oracle-用于δδg预测的图注意力网络微调框架","children":[]},{"level":3,"title":"训练配置","slug":"训练配置","link":"#训练配置","children":[]},{"level":3,"title":"预训练数据集","slug":"预训练数据集","link":"#预训练数据集","children":[]},{"level":3,"title":"cDNA117K 训练集生成","slug":"cdna117k-训练集生成","link":"#cdna117k-训练集生成","children":[]},{"level":3,"title":"C2878 训练集生成","slug":"c2878-训练集生成","link":"#c2878-训练集生成","children":[]},{"level":3,"title":"T2837 测试集生成","slug":"t2837-测试集生成","link":"#t2837-测试集生成","children":[]},{"level":3,"title":"T2837 AlphaFold 结构的生成","slug":"t2837-alphafold-结构的生成","link":"#t2837-alphafold-结构的生成","children":[]},{"level":3,"title":"测试集","slug":"测试集","link":"#测试集","children":[]},{"level":3,"title":"评估指标","slug":"评估指标","link":"#评估指标","children":[]},{"level":3,"title":"Prostata-IFML 细节","slug":"prostata-ifml-细节","link":"#prostata-ifml-细节","children":[]}]}],"relativePath":"pages/posts/Stability Oracle 文献精读.md","path":"/home/runner/work/Valaxy_blog/Valaxy_blog/pages/posts/Stability Oracle 文献精读.md","lastUpdated":1766710824000}'),m=u(),i=e.frontmatter||{};return m.meta.frontmatter=Object.assign(m.meta.frontmatter||{},e.frontmatter||{}),c("pageData",e),c("valaxy:frontmatter",i),globalThis.$frontmatter=i,o({frontmatter:{layout:"post",title:"Stability Oracle 文献精读",date:"2025-10-29 20:19:24",updated:"2025-10-29",time_warning:!0,cover:null,top:null,tags:["ddg"],categories:["生物信息"]}}),(t,r)=>{const p=h;return d(),g(p,{frontmatter:y(i)},{"main-content-md":l(()=>[...r[0]||(r[0]=[a("h1",{id:"stability-oracle-一种基于结构的图transformer框架-用于识别稳定化突变",tabindex:"-1"},[s("Stability Oracle：一种基于结构的图Transformer框架，用于识别稳定化突变 "),a("a",{class:"header-anchor",href:"#stability-oracle-一种基于结构的图transformer框架-用于识别稳定化突变","aria-label":'Permalink to "Stability Oracle：一种基于结构的图Transformer框架，用于识别稳定化突变"'},"​")],-1),a("p",null,[a("a",{href:"https://doi.org/10.1038/s41467-024-49780-2",target:"_blank",rel:"noreferrer"},"Stability Oracle: a structure-based graphtransformer framework for identifying stabilizing mutations")],-1),a("p",null,[a("a",{href:"https://github.com/danny305/StabilityOracle",target:"_blank",rel:"noreferrer"},"https://github.com/danny305/StabilityOracle")],-1),a("h2",{id:"摘要",tabindex:"-1"},[s("摘要 "),a("a",{class:"header-anchor",href:"#摘要","aria-label":'Permalink to "摘要"'},"​")],-1),a("p",null,"工程化稳定蛋白质是工业和医药生物技术发展中的一个根本性挑战。我们提出了Stability Oracle：一种基于结构的图Transformer框架，在准确识别热力学稳定突变方面达到了最先进的（SOTA）性能。我们的框架引入了多项创新，以克服数据稀缺与偏差、泛化能力以及计算时间等方面众所周知的挑战，例如：用于数据增强的热力学置换方法、用于通过单一结构建模突变的结构氨基酸嵌入方法，以及一种蛋白质结构特异性的注意力偏置机制，使Transformer成为图神经网络的有效替代方案。我们提供了可减少数据泄露并确保模型正确评估的训练/测试集划分。此外，为了检验我们的数据工程贡献，我们对ESM2表征进行了微调（Prostata-IFML），并在基于序列的模型中实现了SOTA性能。值得注意的是，尽管Stability Oracle的预训练蛋白质数量比Prostata-IFML少2000倍，且参数量仅为后者的1/548，其性能仍优于Prostata-IFML。我们的框架为基于结构的Transformer微调以适应几乎任何表型建立了路径，这是加速蛋白质生物技术发展的必要任务。",-1),a("h2",{id:"引言",tabindex:"-1"},[s("引言 "),a("a",{class:"header-anchor",href:"#引言","aria-label":'Permalink to "引言"'},"​")],-1),a("p",null,"预测和理解氨基酸替换对蛋白质热力学稳定性（ΔΔG）的影响，是开发基于蛋白质的生物技术（如工业生物催化剂和医药生物制剂）的核心任务。具有增强热力学稳定性的蛋白质更不易发生去折叠和聚集，也更易于进行工程化改造；稳定蛋白质的骨架结构，可以为进一步探索可能影响目标功能但会降低稳定性的突变创造条件。热力学稳定性通过天然状态与去折叠状态之间的吉布斯自由能变化（ΔG）来衡量，反映了蛋白质整体结构的内在完整性。蛋白质的工程化改造过程极为繁琐，已成为基于蛋白质的生物技术发展的瓶颈，因此，开发能够准确预测单点突变ΔΔG并进而识别稳定化突变的计算方法，成为一个极为活跃的研究领域。",-1),a("p",null,"深度学习目前正在彻底改变许多物理和生物学科领域，其中AlphaFold2在2021年引领潮流，被誉为年度科学突破，并引发了一波深度学习结构预测工具的开发热潮。尽管已有多种基于序列和基于结构的深度学习框架被报道用于稳定性预测，但数据匮乏以及机器学习工程方面的问题，阻碍了深度学习算法在蛋白质稳定性预测领域产生类似革命性的影响。",-1),a("p",null,"对过去15年发布的最先进（SOTA）计算稳定性预测工具的系统性分析指出，数据稀缺、数据差异、偏差、数据泄露以及缺乏有效的模型性能评估指标，是阻碍该领域取得实质性进展的关键问题（有关主要数据问题的总结，请参见补充章节B）。因此，研究界目前仍主要依赖基于物理的方法，例如Rosetta和FoldX，或浅层机器学习方法。尽管当前最先进的计算工具在发表时通常报告75-80%的准确率，但这些准确率主要反映的是它们在识别去稳定化突变上的表现，因为测试集中大部分为去稳定化突变，而准确识别这些突变对于发现致病变异至关重要。然而，当由第三方在数据集上评估这些工具对稳定化突变的预测能力时，其预测结果中实际为稳定化突变的比例仅约为20%。尽管稳定化突变在自然界中本就较为稀少，但已有研究表明，对稳定化突变泛化能力差，主要是由于训练集与测试集之间普遍存在数据泄露，以及计算稳定性预测领域所用训练集中严重的类别不平衡问题（去稳定化突变占比超过70%）所致，这些问题必须在机器学习指导的蛋白质工程中得到解决。最后，当前的计算工具主要使用皮尔逊相关系数（Pearson correlation）和均方根误差（RMSE）作为评估指标。由于训练集和测试集中稳定化突变（<30%）与去稳定化突变之间存在显著不平衡，以及测量ΔΔG本身固有的变异性，这些指标的提升并不一定意味着识别稳定化突变的能力有所提高。因此，在开发用于蛋白质工程应用的模型时，也应考虑精确率（precision）、召回率（recall）、受试者工作特征曲线下面积（AUROC）和马修斯相关系数（MCC）等指标（有关指标问题的总结，请参见补充章节B）。",-1),a("p",null,"在这项工作中，我们针对这些关键问题，开发了一个用于蛋白质工程的稳健稳定性预测框架。我们提出了Stability Oracle：一种基于结构的深度学习框架，该框架在数据和机器学习工程方面采用了多项针对稳定性预测的创新技术。Stability Oracle采用了一种图-Transformer架构，将原子视为标记（tokens），并利用它们之间的成对距离，将结构归纳偏置注入到注意力机制中。Stability Oracle的输入包括被删除残基周围的局部化学环境（即被掩蔽的微环境）以及两个氨基酸嵌入，用于表示一个特定的点突变。这一设计决策使得Stability Oracle能够从单个微环境中生成所有380种可能的点突变，从而避免了需要计算生成突变体结构，并使深度突变扫描的推理过程在计算上变得廉价。",-1),a("p",null,"为了提高Stability Oracle的泛化能力，我们引入了一种数据增强技术——热力学置换（Thermodynamic Permutations, TP）。热力学置换类似于热力学可逆性（TR），其基础是吉布斯自由能的状态函数特性。对于蛋白质中的一个特定位置，TP将n个经验ΔΔG测量值扩展为n(n−1)个热力学上有效的测量值，从而根据已通过实验表征了多种氨基酸的残基数量，将数据集规模最多扩大一个数量级（见补充图2）。与TR相比，TP扩大了在训练集或测试集中跨微环境采样的突变类型，减轻了由丙氨酸扫描实验产生的突变类型偏差。此外，与TR不同，TP生成了针对非野生型氨基酸的、平衡的稳定化和去稳定化突变集合。这使我们能够更好地评估蛋白质工程中的泛化能力，因为我们的目标是远离野生型进行突变。",-1),a("p",null,"我们整理了三个数据集（C2878、cDNA117K、T2837）以解决数据泄露问题。使用MMseqs2生成了这三个数据集，并确保训练集和测试集中蛋白质的最大序列相似度低于30%，这是一个处于“暮光区”（twilight zone）的阈值，在此阈值下95%的蛋白质对将具有不同的结构折叠。Concat 2878 (C2878) 和 Test 2837 (T2837) 数据集分别是基于先前建立的训练和测试集重新划分的新训练集和测试集。第三个数据集（cDNA117K）是从cDNA展示蛋白水解数据集中精心筛选出的天然结构域子集，该数据集包含了约85万个热力学折叠稳定性测量值，覆盖了354个天然结构域和188个从头设计的小蛋白结构域（40-72个氨基酸）。后者数据集尤其引人关注，因其规模庞大，并且依赖蛋白水解稳定性作为热力学稳定性的替代指标。",-1),a("p",null,"最后，我们通过在整理好的训练和测试集上使用Prostata框架对ESM2进行微调，为Stability Oracle生成了一个基于序列的对应版本，并训练了Prostata-IFML。利用Prostata-IFML，我们进行了直接对比，以证明基于结构的方法相较于基于序列方法的优势。总体而言，我们证明了Stability Oracle和Prostata-IFML分别是计算稳定性预测领域最先进的基于结构和基于序列的框架。",-1),a("h2",{id:"结果",tabindex:"-1"},[s("结果 "),a("a",{class:"header-anchor",href:"#结果","aria-label":'Permalink to "结果"'},"​")],-1),a("h3",{id:"设计用于基于结构的蛋白质工程的图-transformer框架",tabindex:"-1"},[s("设计用于基于结构的蛋白质工程的图-Transformer框架 "),a("a",{class:"header-anchor",href:"#设计用于基于结构的蛋白质工程的图-transformer框架","aria-label":'Permalink to "设计用于基于结构的蛋白质工程的图-Transformer框架"'},"​")],-1),a("p",null,"在之前的研究中，我们通过实验证明，通过对被掩蔽微环境进行自监督深度学习模型训练所获得的表征（MutCompute 和 MutComputeX），能够识别出与其周围化学环境不协调的氨基酸残基。这些模型可用于“零样本”预测功能获得性点突变，包括在计算得到的蛋白质活性位点结构中的突变。然而，自监督模型生成的突变设计并不偏向于特定表型，也无法根据实验数据更新其预测。MutCompute框架使用体素化的分子表征。对于蛋白质结构而言，体素化是一种次优的分子表示方法，因为大多数体素都是空的空间，且无法编码旋转不变性。此外，MutCompute框架采用基于卷积的架构，这在表征学习能力和预测性能方面落后于现代的基于注意力机制的架构。",-1),a("p",null,"为了开发一个更强大且更具泛化能力的框架以用于下游任务，我们首先构建了MutComputeXGT，即MutComputeX的一个图-Transformer版本（图1a）。每个原子被表示为一个节点，其特征包括原子元素、部分电荷和溶剂可及表面积（SASA）值，原子间的成对距离则作为边的标签。我们的图-Transformer架构将成对距离转换为连续和类别的注意力偏置，从而为注意力机制提供基于结构的归纳偏置。为了生成被掩蔽氨基酸的似然性，我们对距离被掩蔽Cα原子8Å范围内的所有原子标记（atomic tokens）在最终层的隐藏表征进行平均。将池化范围限定在被掩蔽氨基酸第一接触层原子的设计决策，源于在训练自监督3D卷积神经网络时对微环境体积进行系统性变化所获得的洞见。在参数数量相近且使用相同训练-测试集划分的情况下，MutComputeXGT展现出优于MutComputeX的表征学习能力，其野生型氨基酸预测准确率达到92.98% ± 0.26%，而MutComputeX约为85%。",-1),a("p",null,"Stability Oracle架构利用了MutComputeXGT的特征提取器和分类头，用于监督微调（图1b）。以往的基于结构的稳定性预测器需要两个结构——无论是实验结构还是计算结构——来显式地建模野生型和突变型氨基酸。第二个（突变体）结构通常通过AlphaFold或Rosetta等计算方法获得。这种方法的缺点是：（1）在推理阶段，计算方法变得非常耗时（如下所述）；（2）很难评估计算生成的突变体结构的质量。相比之下，Stability Oracle不依赖于第二个结构。更具体地说，局部化学环境（即被掩蔽的微环境）的结构特征是从单一初始结构中提取的，而一个突变则被表示为一对“来源”（from）和“目标”（to）氨基酸嵌入向量。为了建模特定突变的ΔΔG，初始结构的微环境被用于在回归头中对“来源”和“目标”氨基酸嵌入进行上下文化（如图1b所示）。这种架构设计使框架能够隐式地学习“来源”和“目标”氨基酸如何与局部化学环境相互作用，而不是依赖计算结构预测工具来提供化学相互作用信息。",-1),a("p",null,"对于一个典型的300个氨基酸的蛋白质，以往的研究在推理过程中为了预测所有可能的单点突变的ΔΔG，需要生成5700个计算突变体结构（来自Rosetta或AlphaFold）。而Stability Oracle仅需一个结构，即可预测每个残基上所有19种氨基酸替换的ΔΔG（约50毫秒/残基）。不同长度蛋白质的运行时性能指标见补充表1。“来源”和“目标”氨基酸嵌入源自MutComputeXGT分类器最后一层的权重。这一设计决策基于以下洞察：这20个神经元的权重代表了微环境特征与20种氨基酸之间的相似性，在归一化为似然分布之前。因此，它们是基于结构、上下文化的20种氨基酸嵌入，通过在蛋白质数据库（PDB）的50%序列相似性表示上进行自监督预训练获得。我们将这些嵌入称为结构氨基酸嵌入（Structural Amino Acid Embeddings）。",-1),a("p",null,"我们重点介绍Stability Oracle中所用回归头（regression head）的几项设计决策。值得注意的是，我们采用了Siamese（孪生）注意力架构，将突变嵌入（即“来源”和“目标”氨基酸嵌入）视为两个分类（CLS）标记（token）（图1b）。在自然语言处理（NLP）领域，CLS标记常用于捕捉全局上下文信息，以支持下游任务。由于原子和氨基酸是不同尺度上的化学实体，我们设计回归头时，让特定的微环境对“来源”（From）和“目标”（To）这两个氨基酸层级的CLS标记进行上下文化。在给定微环境的上下文中完成信息整合后，这两个氨基酸的CLS标记被相减，从而生成一个代表突变的隐藏表征（mutation-hidden representation），随后该表征被解码为ΔΔG的预测值。这一设计强制实现了吉布斯自由能作为状态函数（state-function）的特性，为热力学可逆性（Thermodynamic Reversibility）和“自突变”（self-mutations，即突变前后氨基酸相同，ΔΔG = 0 kcal/mol）提供了恰当的归纳偏置。例如，当“来源”和“目标”为同一氨基酸时，其CLS向量在上下文化后应高度相似，相减后接近零向量，从而自然地预测出ΔΔG ≈ 0，符合物理规律。",-1),a("h3",{id:"训练-stability-oracle-以泛化至蛋白质化学的各个层面",tabindex:"-1"},[s("训练 Stability Oracle 以泛化至蛋白质化学的各个层面 "),a("a",{class:"header-anchor",href:"#训练-stability-oracle-以泛化至蛋白质化学的各个层面","aria-label":'Permalink to "训练 Stability Oracle 以泛化至蛋白质化学的各个层面"'},"​")],-1),a("p",null,"Stability Oracle框架的设计目标是能够在蛋白质结构中的所有位置上，对全部380种突变类型实现泛化。然而，此类模型的开发在历史上一直受到数据稀缺、偏差和数据泄露等问题的限制。为解决这些问题，我们精心整理了训练和测试数据集，并开发了一种名为热力学置换（Thermodynamic Permutations, TP）的数据增强技术。",-1),a("p",null,[s("众所周知，以往研究中的一个主要问题是训练集和测试集中包含了相似的蛋白质（“数据泄露”），这导致对模型泛化能力的评估严重失真。已有研究表明，按突变、残基或蛋白质层面划分训练集和测试集会导致模型在验证集上过拟合，因此必须采用严格的序列聚类方法，才能确保对泛化能力进行正确的评估。为此，我们基于 MMSeqs2 计算的30%序列相似性阈值，创建了新的训练-测试集划分。首先，我们构建了T2837测试集，然后利用该测试集从剩余的实验数据中剔除所有同源蛋白质，从而生成C2878训练集。同样的流程也被用于从最近发表的cDNA展示蛋白水解数据集中，从具有实验结构的单突变子集中构建cDNA117K训练集（图2）。 "),a("img",{src:"https://cloudflare.remsait.com/img/StabilityOracle202510281515599.png",alt:""}),s(" 即使使用了扩展后的T2837测试集，我们仍然无法评估14%的380种突变类型的泛化性能，因为这些突变类型在T2837中没有数据。此外，T2837中对丙氨酸的突变存在严重偏差（图3a，底行），这进一步限制了我们评估模型泛化能力的能力。研究界传统上依赖于数据增强技术“热力学可逆性”（TR） 来生成覆盖更广突变类型的训练数据集（见补充图2）。然而，在C2878 + TR 和 T2837 + TR 数据集中，仍有约3%的突变类型缺乏数据（见补充图3）。更重要的是，TR增强的一个主要缺陷是："),a("strong",null,"它所生成的所有稳定化突变都是指向野生型氨基酸的"),s("（如图3b所示）。这类突变对于识别非野生型的稳定化突变没有任何预测价值，而后者正是蛋白质工程背景下热力学稳定性预测的主要目标。为了提升深度学习框架在蛋白质稳定化方面的预测能力，迫切需要更多关于不指向野生型氨基酸的稳定化突变的数据。（"),a("strong",null,"TR就是生成反向突变；TP是两个突变型做差，从一个突变型出发变成另一个突变型")],-1),a("p",null,"为了解决上述问题并提升Stability Oracle的泛化能力，我们引入了一种数据增强技术——热力学置换（Thermodynamic Permutations, TP）。TP基于吉布斯自由能的状态函数特性，能够在已有多个氨基酸被实验表征的残基位置上，生成热力学上有效的点突变数据。通过TP，我们分别为cDNA117K、C2878和T2837数据集额外生成了202万、1.89万和7,700个点突变数据，这些新增数据覆盖了全部380种突变类型。此外，TP缓解了这三个数据集中存在的多种采样偏差（图3a，中间列）。首先，它为在C2878和T2837中缺失的13.2%和14.5%的突变类型提供了数据。经过TP增强后，C2878和T2837的数据覆盖了全部380种突变类型，从而首次构建了包含所有突变类型实验ΔΔG测量值的训练集和测试集（需要说明的是，cDNA展示蛋白水解数据集并非直接测量ΔΔG，而是通过多重蛋白水解实验的下一代测序数据推导出ΔΔG值）。",-1),a("p",null,"图3a展示了采样偏差的改善情况：红色区域（过采样）和蓝色区域（欠采样）向白色（均衡采样）趋近，颜色逐渐变淡。在C2878和T2837数据集中，这种改善最明显地体现在原先对“突变为”丙氨酸（“to” alanine）的采样偏差上。在cDNA117K数据集中，存在“源自”丙氨酸、谷氨酸、亮氨酸和赖氨酸的突变被过采样，而“源自”半胱氨酸、组氨酸、甲硫氨酸和色氨酸的突变则被欠采样的偏差。TP完全平衡了cDNA117K中的突变类型分布，每种突变类型在数据集中占比约为0.26%（100%/380），如图3a中间列、中间行所示，呈现出均匀的白色。因此，经过TP增强的cDNA117K提供了首个大规模（超过100万条）ΔΔG数据集，该数据集在100个蛋白质结构域中均匀采样了全部380种突变类型。与热力学可逆性（TR）不同，TP不包含指向野生型氨基酸的稳定化突变，并且生成的ΔΔG测量值在稳定化与去稳定化之间呈现出均衡的分布（图3b）。",-1),a("p",null,"为了开发Stability Oracle框架，我们比较了在cDNA117K和/或C2878数据集上进行训练的效果，分别使用了有和没有TP增强的数据，并对比了采用结构氨基酸嵌入（Structural Amino Acid Embeddings）与简单的独热编码（one-hot encodings）的性能，最终在所有测试集上评估了模型表现。我们观察到，与图4a中朴素的独热编码相比，使用结构氨基酸嵌入显著提升了模型性能。对T2837突变隐藏表征（mutation-hidden representation）进行UMAP可视化分析显示，来自结构氨基酸嵌入的“目标氨基酸”（ToAA）CLS标记主导了潜在空间的组织结构，并恢复了20种氨基酸之间已知的生化关系，如图5a所示。我们观察到以下几点：1）疏水性氨基酸（LEU、VAL、ILE、MET）、芳香族氨基酸（PHE、TYR、TRP）以及短链极性氨基酸（SER、THR 和 ASP、ASN）形成聚类（右侧面板）；2）特殊氨基酸（GLY、CYS、PRO）彼此分离（右侧面板）；3）从甘氨酸（GLY）突变并引入手性侧链的独特情况（左侧面板）。关于380种突变类型的残基特异性案例研究，请参见补充图7。",-1),a("p",null,"关于训练数据集的选择，在回归和分类指标上的综合表现表明，使用cDNA117K + TP + TR进行自监督表征训练的整体效果最佳（如图4b/c所示）。尽管这可能是由于其数据规模更大且突变类型分布更均衡，相较于C2878 + TP + TR具有天然优势，但值得注意的是，这一结果也印证了原始研究中的观点：单结构域天然蛋白的蛋白水解稳定性实际上是热力学稳定性的极佳替代指标。然而，从这些结果中尚不明确TP对模型泛化能力的具体影响。为了进一步探究TP增强数据集如何影响泛化性能，我们专门评估了那些在C2878 + TR中缺失但在C2878 + TP + TR中存在的突变类型在T2837 + TP上的预测表现——即那12种原本没有任何实验数据的突变类型（见补充图3）。对于这些突变类型，TP显著提升了泛化能力：召回率（recall）从0.28提升至0.40，精确率（precision）从0.47提升至0.67（图6）。我们将缺失数据的突变类型人为扩展至54种，仍观察到了类似但程度有所减弱的精确率和召回率提升（图6）。",-1),a("p",null,"为了防止Stability Oracle分类性能的虚高，我们将评估重点放在T2837 + TP（共10,557个突变）上，并排除所有通过热力学可逆性（TR）生成的突变，因为这些突变严重偏向于指向野生型氨基酸的稳定化突变（见补充图4）。在此设置下，Stability Oracle表现出0.69的召回率（recall）、0.70的精确率（precision）以及0.83的AUROC值（图4b）。令人意外的是，在C2878 + TP上进一步微调并未提升模型在T2837或T2837 + TP上的性能。我们的分析显示，C2878中的所有蛋白质都与cDNA117K中的至少一个蛋白质具有同源性（序列相似性 > 30%），因此C2878并未扩展可用于训练的蛋白质空间。这一发现解释了为何在C2878上进一步微调未能带来性能提升。",-1),a("p",null,"然而，在T2837的界面子集（interface subset）上，C2878的微调确实带来了性能提升：界面微环境的皮尔逊相关系数（Pearson correlation）从0.30提升至0.35，斯皮尔曼相关系数（Spearman correlation）从0.29提升至0.35。这一提升是可预期的，因为cDNA数据集仅包含单体单结构域蛋白，缺乏与其他蛋白质、配体或核酸的相互作用界面。但由于C2878中蛋白质-蛋白质（127个突变）、蛋白质-配体（94个突变）和蛋白质-核酸（9个突变）的数据量极为有限，因此性能的提升幅度也受到限制。",-1),a("p",null,"由于实验结构往往难以获得，我们评估了Stability Oracle在AlphaFold2生成的结构上的泛化能力，这些结构包含野生型（WT）以及“来源”（From）和“目标”（To）氨基酸。我们使用ColabFold为T2837中的每个蛋白质生成了无模板的预测结构。其中，一个蛋白质未能成功折叠，另有两个结构因TM-align的USscore < 0.5而被剔除，导致T2837中50个突变被移除。在使用AlphaFold预测的野生型结构对T2837和T2837 + TP进行评估时，我们发现分类指标没有变化，而在T2837 + TP上的回归性能略有下降（图4d）。接着，我们进一步评估了“来源”和“目标”氨基酸对应的AlphaFold突变体结构对仅含TP增强数据的T2837子集（T2837 TP-only dataset，共7720个突变，100%覆盖所有380种突变类型）的影响，结果观察到分类和回归指标均下降了2–4%（见补充表4）。总体而言，这些结果表明，当缺乏实验结构时，Stability Oracle仍具备在AlphaFold预测骨架上有效泛化的能力，性能下降有限，展现出良好的实用性与鲁棒性。",-1),a("p",null,"我们进行了多项与现有文献方法的对比。首先，我们在T2837以及多个常用的测试集上报告了皮尔逊相关系数（PCC）（包括正向和反向）。对于这些常用测试集，我们在图7中与多个社区广泛使用的预测工具进行了比较，并在补充表5a中提供了在文献测试集上的全部分类与回归指标。值得注意的是，即使与其他存在已知数据泄露问题的预测模型相比，Stability Oracle依然在性能上超越了现有方法。迄今为止，文献中最准确且最全面的热力学稳定性数据集是Gβ1数据集。我们在该数据集上评估了Stability Oracle的性能，据我们所知，在全部935个突变上实现了当前最优（SOTA）的表现（皮尔逊相关系数 = 0.75，AUROC = 0.84）；在其中包含定量ΔΔG值的835个突变子集上，同样达到SOTA水平（皮尔逊相关系数 = 0.67，AUROC = 0.81）。完整结果见补充表6。最后，我们以p53蛋白为例，对Stability Oracle的结构敏感性进行了案例研究。结构敏感性是此前文献中报道过的基于结构的稳定性预测工具存在的一个问题。我们评估了三个p53结构（PDB编号：2OCJ、3Q05、2AC0），它们在蛋白长度（94-312、94-326、94-293）、分辨率（2.05 Å、2.40 Å、1.80 Å）以及生物组装形式（无DNA的同源二聚体、结合一条DNA双螺旋的同源四聚体、结合两条DNA双螺旋的同源四聚体）方面均有所不同，这些结构的可视化见补充图1a。该案例研究表明，尽管p53的结构存在显著差异，Stability Oracle仍表现出良好的泛化能力，其性能为：皮尔逊相关系数 = 0.75 ± 0.02，斯皮尔曼相关系数 = 0.76 ± 0.05，精确率 = 0.55 ± 0.07，AUROC = 0.83 ± 0.02（完整结果见补充图1b）。这一结果进一步验证了Stability Oracle在面对真实世界中结构多样性时的稳健性。",-1),a("h3",{id:"评估stability-oracle识别稳定化突变的能力",tabindex:"-1"},[s("评估Stability Oracle识别稳定化突变的能力 "),a("a",{class:"header-anchor",href:"#评估stability-oracle识别稳定化突变的能力","aria-label":'Permalink to "评估Stability Oracle识别稳定化突变的能力"'},"​")],-1),a("p",null,"为了使计算稳定性预测工具能够加速蛋白质工程进程，其预测结果必须能够准确识别出真正具有稳定作用的突变。然而，已有大量研究明确指出，当前最先进的（SOTA）稳定性预测工具在识别稳定化突变时的成功率仅约为20%，且大多数被预测为“稳定化”的突变在实验中实际上是中性的，甚至是去稳定化的。尽管基于分子动力学的方法（如自由能微扰法，FEP）在识别稳定化突变方面已展现出约50%的成功率，但其巨大的计算开销使其难以扩展到全蛋白范围的应用，例如计算深度突变扫描（computational deep mutational scans, DMS）。因此，领域内迫切需要一种既能达到FEP级别预测性能、又具有较低计算成本的新方法。",-1),a("p",null,"为了评估Stability Oracle识别稳定化突变的能力，我们在不同ΔΔG预测阈值下对其在T2837和T2837 + TP上的预测结果进行了筛选，并分析了实验测定中稳定化（ΔΔG < −0.5 kcal/mol）、中性（∣ΔΔG∣ ≤ 0.5 kcal/mol）和去稳定化（ΔΔG > 0.5 kcal/mol）突变的分布情况。选择0.5 kcal/mol作为截断值是基于平均实验误差的考量。当采用ΔΔG < −0.5 kcal/mol作为预测阈值时，共筛选出1770个突变，其中实验结果显示：74.0%为稳定化突变，17.8%为中性突变，8.2%为去稳定化突变；同时，模型正确识别出了全部实验稳定化突变中的48.1%。不同预测阈值的系统性分析见图8和补充表8a。该方法预测稳定化突变的成功率（74%）似乎超过了通常报道的FEP方法的水平（约50%）³³,⁶⁹，且计算成本降低了数个数量级（见补充表1）。我们进一步按氨基酸类别分析了Stability Oracle识别稳定化突变的能力（图5b）。结果表明，无论是“来源”还是“目标”氨基酸，Stability Oracle均能在大多数氨基酸上正确预测出稳定化突变。然而，部分氨基酸的“来源”或“目标”类别的稳定化预测样本量不足，难以得出有意义的结论。当进一步细化到380种具体的“来源-目标”氨基酸对时，数据稀缺问题更加明显（见补充图5），凸显了当前数据匮乏仍在严重制约对模型性能的全面评估。",-1),a("p",null,"研究社区已指出，实验表征的表面稳定化突变存在偏向于疏水性氨基酸的偏差。Broom等人对ProTherm数据库的分析表明，表面稳定化突变通常会增加侧链的疏水性（ΔΔGsolvation），中位变化值为0.8 kcal/mol。这种疏水性偏差相当于在蛋白质表面发生一次丙氨酸到缬氨酸的突变。为了检验这种潜在的疏水性偏差是否存在于我们的训练流程中，我们计算了在不同野生型残基相对溶剂可及性（RSA）条件下，模型对极性和疏水性突变的预测精确率（precision）和召回率（recall）。我们在T2837及T2837 + TP数据集上按不同RSA区间进行的分析结果显示，使用cDNA117K + TP训练集所训练的模型并未产生倾向于预测蛋白质表面为疏水性氨基酸的偏差（图9）。这表明，我们的数据增强方法（TP）和训练策略有效缓解了传统数据库中存在的疏水性偏好问题，提升了模型在表面残基突变预测上的公平性与可靠性。",-1),a("h3",{id:"比较基于序列与结构的微调稳定性预测模型",tabindex:"-1"},[s("比较基于序列与结构的微调稳定性预测模型 "),a("a",{class:"header-anchor",href:"#比较基于序列与结构的微调稳定性预测模型","aria-label":'Permalink to "比较基于序列与结构的微调稳定性预测模型"'},"​")],-1),a("p",null,"在过去三年中，自监督蛋白质大语言模型（pLLMs，或称“序列模型”）对蛋白质研究领域产生了巨大影响。理解基于序列与基于结构的预测模型之间的差异，仍是蛋白质工程与设计领域的活跃研究方向。我们对Stability Oracle与两种计算稳定性深度学习框架——Prostata和RaSP——进行了比较。",-1),a("p",null,"Prostata 是一种基于序列的框架，它在五个不同的回归头结构上集成微调ESM2嵌入（一种当前最先进的蛋白质语言模型），并在常见的训练集和测试集上进行训练。然而，Prostata在训练时使用了与SSym和S669测试集同源的蛋白质（序列相似性阈值为75%），导致其在T2837及其子集测试集上的性能被高估（性能虚高及数据泄露的具体分析见补充表7）。为消除数据泄露并实现公平比较，我们使用与Stability Oracle相同的训练集和测试集，仅采用外积（outer-product）回归头架构，对ESM2的表征进行了重新微调。我们将这一版本称为 Prostata-IFML（Informed Fine-tuning with Matched Leakage control）。",-1),a("p",null,"我们还与 RaSP框架 进行了对比。RaSP是一种基于结构的三维卷积神经网络（3DCNN）模型，其训练流程与Stability Oracle类似：首先，在从2315个蛋白质结构（按30%序列相似性聚类）中采样的18Å掩蔽微环境上进行自监督预训练；随后，在由Rosetta Cartesian-ΔΔG程序计算生成的35个深度突变扫描（DMS）数据集上进行微调。在我们的分析中，我们修改了RaSP的Colab笔记本代码，使其能够对T2837中的每个蛋白质以及T2837 + TP中的每一个突变生成DMS预测结果，从而确保评估条件的一致性和可比性。",-1),a("p",null,"Stability Oracle在所有指标上均优于或至少与Prostata-IFML持平（图10），而其模型参数量仅为后者的1/548（约120万 vs. 约6580万），且预训练所用的蛋白质数量在相同序列相似性阈值（50%）下比Prostata少2000倍（约2.3万 vs. 约4600万）。这一结果表明，Stability Oracle在显著更小的模型规模和更有限的预训练数据下，依然实现了更强或相当的泛化能力，凸显了其架构设计与数据增强策略的有效性。",-1),a("p",null,"相比之下，RaSP的表现则明显落后。在T2837和T2837 + TP两个测试集上，Stability Oracle在几乎所有分类与回归指标上均显著优于RaSP。仅在T2837上的皮尔逊相关系数（Pearson）和T2837 + TP上的精确率（precision）上表现接近。在识别稳定化突变方面，Stability Oracle同样表现最佳（图8）。在每一个ΔΔG预测阈值下，Stability Oracle都拥有最高比例的正确识别的稳定化突变，以及最低比例的被错误预测为稳定化实则去稳定化的突变（由于数据不足，T2837在−1.5 kcal/mol阈值下的结果被排除）。",-1),a("p",null,"通常情况下，精确率（precision）与召回率（recall）呈此消彼长的关系。我们在T2837 + TP上的结果也观察到了这一权衡：Prostata-IFML的召回率更高，但精确率略低。我们推测这一差异可能源于两者采用的损失函数不同：Stability Oracle使用Huber损失，而Prostata使用均方误差（MSE）。尽管如此，无论是Stability Oracle还是Prostata-IFML，在准确识别稳定化突变（高精确率）和尽可能多地发现稳定化突变（高召回率）两方面，均远优于RaSP。详细对比见补充表8。",-1),a("p",null,"与此同时，另一项并行研究开发了ThermoMPNN——一种基于微调ProteinMPNN表征的深度学习框架，同样在大规模cDNA蛋白水解数据集上训练。我们使用其公开的模型检查点进行了评估，发现Stability Oracle在SSym、S669、肌红蛋白（myoglobin）和p53等多个标准测试集上，于多种回归与分类指标上均优于ThermoMPNN（见补充表10）。",-1),a("p",null,"最后，我们比较了三种框架对自突变（self-mutations）的预测能力：即“来源”与“目标”氨基酸相同，ΔΔG理论值为0 kcal/mol。类似于正向与反向突变实验用于评估预测器的热力学鲁棒性，自突变测试评估的是模型对训练集中未出现但符合热力学原理的“平凡”情况的泛化能力。在T2837上的野生型自突变测试中，Stability Oracle、Prostata-IFML和RaSP的均方根误差（RMSE）分别为0.0033、0.0018和0.8370 kcal/mol。这表明，Stability Oracle和Prostata-IFML能够隐式地学习并捕捉自突变应为零的物理规律，而RaSP则完全无法泛化到此类情况，其性能急剧下降。这一问题在对T2837进行TR数据增强后同样被观察到（见补充表9c），进一步揭示了RaSP在热力学一致性建模上的根本缺陷。",-1),a("h2",{id:"讨论",tabindex:"-1"},[s("讨论 "),a("a",{class:"header-anchor",href:"#讨论","aria-label":'Permalink to "讨论"'},"​")],-1),a("p",null,"可靠地预测稳定化突变对于加速基于蛋白质的生物技术发展至关重要。然而，截至2023年3月，所有现有的计算稳定性预测工具都主要关注皮尔逊相关系数（Pearson）和均方根误差（RMSE）等回归指标的提升。然而，这些指标并不适合评估模型在识别稳定化突变能力上的改进，已有多个研究对此进行了详细阐述。我们在报告这些回归指标的同时，采用AUROC、MCC、召回率（recall）和精确率（precision）等分类指标来指导模型的开发与优化。",-1),a("p",null,"通过采用30%序列相似性阈值进行训练集与测试集的划分，我们避免了传统划分方法中因同源蛋白泄露导致的数据泄露问题，从而确保Stability Oracle和Prostata-IFML具备更强的泛化能力。实验结果表明，Stability Oracle和Prostata-IFML在识别稳定化突变方面可能已超越基于自由能微扰（FEP）的方法，同时计算速度提升了数个数量级。然而，这一结论仍需通过与FEP方法的系统性直接对比实验来进一步验证。",-1),a("p",null,"近年来，文献中广泛采用热力学可逆性（Thermodynamic Reversibility, TR）来缓解训练和测试集中稳定化与去稳定化突变之间的不平衡问题。然而，TR会引入新的偏差：它倾向于生成指向野生型氨基酸的稳定化突变。对于依赖进化信息和蛋白质结构作为输入的计算模型而言，这类突变实际上泄露了关于野生型残基的信息，在蛋白质工程的实际场景中用途有限——因为工程目标通常是突变离开野生型，而非返回。为此，我们提出了热力学置换（Thermodynamic Permutations, TP）这一数据增强技术。TP生成的突变具有平衡的ΔΔG分布，且不会生成指向野生型氨基酸的突变（见补充图3b）。这一特性有效缓解了上述不平衡问题，并在训练集和测试集中显著增加了非野生型氨基酸的稳定化突变样本。此外，TP还有助于减轻自监督预训练阶段对野生型残基的固有偏好。",-1),a("p",null,"我们推测，在端到端微调过程中，TP迫使特征提取器在局部微环境中寻找更多与化学稳定性相关的信号，而不仅仅是识别野生型残基的特征。更重要的是，TP还能为那些在实验中极少被表征的微环境-突变类型组合生成ΔΔG数据，从而扩展了可用于训练和测试的结构-突变组合空间，极有可能提升模型在不同蛋白质结构模体上的泛化能力。然而，目前尚缺乏足够的实验测试数据来系统验证这一假设。我们预计，TP技术将在开发用于高阶突变（如双突变、多点突变）预测的框架中发挥巨大作用，因为在这些场景下，数据稀缺问题更为严峻。通过TP生成的热力学一致且多样化的数据，有望为下一代蛋白质稳定性预测与设计模型提供更坚实的基础。",-1),a("p",null,"值得注意的是，Stability Oracle在模型参数量远小于Prostata-IFML的情况下仍能实现相当甚至更优的性能。这一结果有力地表明：蛋白质结构中蕴含的信息超越了氨基酸序列本身。传统的自监督深度学习模型（如MutComputeX）在预测蛋白核心区域的突变时通常表现不佳，往往倾向于在高度紧密堆积的环境中重新预测回野生型残基。而Stability Oracle则通过显式地从局部微环境中学习稳定化取代模式，提供了一种基于结构的、专门针对核心突变的有效预测方法。",-1),a("p",null,"在训练数据规模方面，值得注意的是：仅使用约2.5万个热力学ΔΔG测量值（C2878 + TP + TR）训练的模型，其性能已可与那些在约220万个蛋白水解稳定性数据（cDNA117K + TP + TR）上训练的模型相媲美。尽管T2837目前仍是一个有限的评估集，但这一现象明确提示我们：数据的质量与数量同样重要。未来，若能发展更多实验技术，以生成更大规模、包含详细热力学信息的数据集——尤其是针对功能界面残基的数据——将有望进一步提升模型的泛化能力。",-1),a("p",null,"准确识别稳定化突变的能力将持续影响众多领域，例如：设计更稳定、保质期更长的蛋白质药物和疫苗；开发可在高温下工作的酶，用于生物制造和环境修复等。尽管先前的算法（如MutCompute）已被证明能有效提升蛋白质稳定性，但Stability Oracle凭借在多种指标上的更高精度，有望进一步提高功能性稳定突变的命中率。",-1),a("p",null,"更重要的是，Stability Oracle关注的是热力学效应，而不仅仅是空间位阻（sterics）。这使得它能够对更广泛的取代类型做出可靠预测，包括在蛋白质-蛋白质界面（如抗体-抗原相互作用）、蛋白质-配体界面以及蛋白质-核酸界面上的突变，从而为复杂生物分子系统的理性设计提供更强大、更具物理一致性的计算工具。",-1),a("h2",{id:"方法",tabindex:"-1"},[s("方法 "),a("a",{class:"header-anchor",href:"#方法","aria-label":'Permalink to "方法"'},"​")],-1),a("h3",{id:"模型架构",tabindex:"-1"},[s("模型架构 "),a("a",{class:"header-anchor",href:"#模型架构","aria-label":'Permalink to "模型架构"'},"​")],-1),a("p",null,"我们构建了一个基于Transformer的神经网络，用于同时支持掩码氨基酸自监督学习（mask amino acid self-supervised learning）和ΔΔG监督学习（ΔΔG supervised learning）。以下分别描述用于自监督预训练的主干模型架构（backbone model）和用于ΔΔG预测的回归头架构（regression head）。",-1),a("h3",{id:"mutcomputexgt-用于氨基酸概率预测的自监督图注意力网络模型",tabindex:"-1"},[s("MutComputeXGT：用于氨基酸概率预测的自监督图注意力网络模型 "),a("a",{class:"header-anchor",href:"#mutcomputexgt-用于氨基酸概率预测的自监督图注意力网络模型","aria-label":'Permalink to "MutComputeXGT：用于氨基酸概率预测的自监督图注意力网络模型"'},"​")],-1),a("p",null,"我们首先介绍用于自监督任务的图注意力（graph transformer）模型，概述其关键组成部分与主要设计。接着，我们给出模型的整体结构，并列出模型的输入与输出。最后，我们详细阐述模型中的若干关键归纳偏置设计。",-1),a("p",null,"总体而言，在我们的任务中，模型的输入是目标氨基酸的局部环境。给定一个氨基酸，我们以其α碳（Cα）为中心，截取半径为 n 范围内的所有原子。在自监督训练的背景下，我们对目标氨基酸内的每个原子进行掩码（masking），并预测其对应的氨基酸类型。该方法结合了基于图的表示和自监督学习，以捕获重要的结构特征，从而增强我们对蛋白质序列的理解。",-1),a("p",null,[s("设 N 为原子（token）的数量，模型输入包括坐标矩阵"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mo",null,"∈"),a("msup",null,[a("mi",null,"R"),a("mrow",null,[a("mi",null,"N"),a("mo",null,"×"),a("mn",null,"3")])])]),a("annotation",{encoding:"application/x-tex"},"\\in R^{N×3}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.5782em","vertical-align":"-0.0391em"}}),a("span",{class:"mrel"},"∈"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8413em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8413em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mbin mtight"},"×"),a("span",{class:"mord mtight"},"3")])])])])])])])])])])]),s("、原子类型矩阵"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mo",null,"∈"),a("msup",null,[a("mi",null,"R"),a("mrow",null,[a("mi",null,"N"),a("mo",null,"×"),a("mn",null,"1")])])]),a("annotation",{encoding:"application/x-tex"},"\\in R^{N×1}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.5782em","vertical-align":"-0.0391em"}}),a("span",{class:"mrel"},"∈"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8413em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8413em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mbin mtight"},"×"),a("span",{class:"mord mtight"},"1")])])])])])])])])])])]),s("，以及物理属性矩阵 "),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"p"),a("mo",null,"∈"),a("msup",null,[a("mi",null,"R"),a("mrow",null,[a("mi",null,"N"),a("mo",null,"×"),a("mi",null,"P")])])]),a("annotation",{encoding:"application/x-tex"},"p \\in R^{N×P}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.7335em","vertical-align":"-0.1944em"}}),a("span",{class:"mord mathnormal"},"p"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},"∈"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8413em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8413em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mbin mtight"},"×"),a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"P")])])])])])])])])])])]),s("。模型首先通过嵌入层（embedding layer）将类别型的原子类型映射为连续表示"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"e"),a("mo",null,"∈"),a("msup",null,[a("mi",null,"R"),a("mrow",null,[a("mi",null,"N"),a("mo",null,"×"),a("mi",null,"E")])])]),a("annotation",{encoding:"application/x-tex"},"e \\in R^{N×E}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.5782em","vertical-align":"-0.0391em"}}),a("span",{class:"mord mathnormal"},"e"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},"∈"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8413em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8413em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mbin mtight"},"×"),a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05764em"}},"E")])])])])])])])])])])]),s("，其中 E = 20 表示氨基酸种类数。然后，将该嵌入向量与物理属性拼接得到 h = Concat(e,p)。")],-1),a("p",null,[s("坐标矩阵"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mo",null,"∈"),a("msup",null,[a("mi",null,"R"),a("mrow",null,[a("mi",null,"N"),a("mo",null,"×"),a("mn",null,"3")])])]),a("annotation",{encoding:"application/x-tex"},"\\in R^{N×3}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.5782em","vertical-align":"-0.0391em"}}),a("span",{class:"mrel"},"∈"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8413em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8413em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mbin mtight"},"×"),a("span",{class:"mord mtight"},"3")])])])])])])])])])])]),s("用于计算原子间的欧氏距离矩阵"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"D"),a("mo",null,"∈"),a("msup",null,[a("mi",null,"R"),a("mrow",null,[a("mi",null,"N"),a("mo",null,"×"),a("mi",null,"N")])])]),a("annotation",{encoding:"application/x-tex"},"D \\in R^{N×N}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.7224em","vertical-align":"-0.0391em"}}),a("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"D"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},"∈"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8413em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8413em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mbin mtight"},"×"),a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N")])])])])])])])])])])]),s("，该距离矩阵在注意力层中作为注意力偏置（attention bias）。拼接后的特征 h 依次通过若干个注意力块（attention block）。每个注意力块包含两个注意力层和一个 MLP 层。MLP 层与标准注意力块相同，而在每个注意力层中，在计算 "),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"K"),a("msup",null,[a("mi",null,"Q"),a("mi",null,"T")])]),a("annotation",{encoding:"application/x-tex"},"KQ^{T}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"1.0358em","vertical-align":"-0.1944em"}}),a("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"K"),a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"Q"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8413em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"T")])])])])])])])])])])]),s("后，我们额外引入注意力掩码（attention mask）与注意力偏置项。")],-1),a("p",null,[s("注意力偏置基于距离矩阵 D 计算。给定 D ，我们生成多个特征向量，并为每个注意力头输出一个偏置项。通过对距离使用 K = 16 个带不同带宽的径向基函数（RBF），得到 "),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"k"),a("mo",null,"∈"),a("msup",null,[a("mi",null,"R"),a("mrow",null,[a("mi",null,"N"),a("mo",null,"×"),a("mi",null,"N"),a("mo",null,"×"),a("mi",null,"K")])])]),a("annotation",{encoding:"application/x-tex"},"k \\in R^{N×N×K}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.7335em","vertical-align":"-0.0391em"}}),a("span",{class:"mord mathnormal",style:{"margin-right":"0.03148em"}},"k"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},"∈"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8413em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8413em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mbin mtight"},"×"),a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mbin mtight"},"×"),a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07153em"}},"K")])])])])])])])])])])]),s("；同时，将距离划分为 C = 4 个类别，得到 "),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"c"),a("mo",null,"∈"),a("msup",null,[a("mi",null,"R"),a("mrow",null,[a("mi",null,"N"),a("mo",null,"×"),a("mi",null,"N"),a("mo",null,"×"),a("mi",null,"C")])])]),a("annotation",{encoding:"application/x-tex"},"c \\in R^{N×N×C}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.5782em","vertical-align":"-0.0391em"}}),a("span",{class:"mord mathnormal"},"c"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},"∈"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8413em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8413em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mbin mtight"},"×"),a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mbin mtight"},"×"),a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07153em"}},"C")])])])])])])])])])])]),s("。在将 c 与 k 拼接后施加线性变换，得到偏置张量"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mo",null,"∈"),a("msup",null,[a("mi",null,"R"),a("mrow",null,[a("mi",null,"N"),a("mo",null,"×"),a("mi",null,"N"),a("mo",null,"×"),a("mi",null,"H"),a("mi",null,"e"),a("mi",null,"a"),a("mi",null,"d")])])]),a("annotation",{encoding:"application/x-tex"},"\\in R^{N×N×Head}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.5782em","vertical-align":"-0.0391em"}}),a("span",{class:"mrel"},"∈"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8491em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8491em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mbin mtight"},"×"),a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mbin mtight"},"×"),a("span",{class:"mord mathnormal mtight"},"He"),a("span",{class:"mord mathnormal mtight"},"a"),a("span",{class:"mord mathnormal mtight"},"d")])])])])])])])])])])]),s("，其中 Head 表示单个注意力层中的注意力头数。")],-1),a("p",null,"最后，我们收集所有原子的隐藏表示 h 并选择那些与被掩码氨基酸相邻的原子。具体而言，我们以被掩码氨基酸的α碳为中心，选取半径 8 Å 内的所有原子。将这些原子token的特征进行平均池化（average pooling），并输入分类器，最终归一化为 20 种氨基酸的可能性分布。分类器由一个 “Linear–ReLU–Linear” 模块组成，其两层线性层的神经元数分别为 128 和 20。",-1),a("h3",{id:"stability-oracle-用于δδg预测的图注意力网络微调框架",tabindex:"-1"},[s("Stability Oracle：用于ΔΔG预测的图注意力网络微调框架 "),a("a",{class:"header-anchor",href:"#stability-oracle-用于δδg预测的图注意力网络微调框架","aria-label":'Permalink to "Stability Oracle：用于ΔΔG预测的图注意力网络微调框架"'},"​")],-1),a("p",null,"Stability Oracle框架包含两个部分：一个用于编码被掩码局部微环境的主干网络（backbone），以及一个用于预测稳定性的回归头（regression head）。在本节中，我们主要关注回归头的架构设计，因为主干网络的权重来自前述自监督学习任务的预训练模型，并在此基础上进行微调。",-1),a("p",null,[s("我们的目标是：给定一个被掩码的局部微环境，以及两种氨基酸类型（一种是野生型，另一种是突变后的氨基酸），预测由此突变引起的折叠自由能变化（ΔΔG）。首先，我们从主干网络中提取有用的原子特征。对于输入的局部微环境，我们将其传入主干网络，得到输出表示"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"h"),a("mo",null,"∈"),a("msup",null,[a("mi",null,"R"),a("mrow",null,[a("mi",null,"N"),a("mo",null,"×"),a("mi",null,"H")])])]),a("annotation",{encoding:"application/x-tex"},"h \\in R^{N×H}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.7335em","vertical-align":"-0.0391em"}}),a("span",{class:"mord mathnormal"},"h"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),a("span",{class:"mrel"},"∈"),a("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.8413em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.8413em"}},[a("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N"),a("span",{class:"mbin mtight"},"×"),a("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.08125em"}},"H")])])])])])])])])])])]),s("，其中 H 表示隐藏层维度。")],-1),a("p",null,[s("接着，根据给定的野生型和突变型氨基酸类型，我们从主干网络最后一层的线性层中提取对应的氨基酸嵌入向量，分别记为e_{wt} \\in R&{1×H}和e_{mut} \\in R&{1×H}。然后，我们将主干网络输出的原子特征 h 分别与这两个嵌入向量拼接，即执行 "),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"C"),a("mi",null,"o"),a("mi",null,"n"),a("mi",null,"c"),a("mi",null,"a"),a("mi",null,"t"),a("mo",{stretchy:"false"},"("),a("mi",null,"h"),a("mo",{separator:"true"},","),a("msub",null,[a("mi",null,"e"),a("mrow",null,[a("mi",null,"w"),a("mi",null,"t")])]),a("mo",{stretchy:"false"},")")]),a("annotation",{encoding:"application/x-tex"},"Concat(h, e_{wt})")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),a("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"C"),a("span",{class:"mord mathnormal"},"o"),a("span",{class:"mord mathnormal"},"n"),a("span",{class:"mord mathnormal"},"c"),a("span",{class:"mord mathnormal"},"a"),a("span",{class:"mord mathnormal"},"t"),a("span",{class:"mopen"},"("),a("span",{class:"mord mathnormal"},"h"),a("span",{class:"mpunct"},","),a("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"e"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t vlist-t2"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.2806em"}},[a("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight"},"wt")])])])]),a("span",{class:"vlist-s"},"​")]),a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.15em"}},[a("span")])])])])]),a("span",{class:"mclose"},")")])])]),s("和"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("mi",null,"C"),a("mi",null,"o"),a("mi",null,"n"),a("mi",null,"c"),a("mi",null,"a"),a("mi",null,"t"),a("mo",{stretchy:"false"},"("),a("mi",null,"h"),a("mo",{separator:"true"},","),a("msub",null,[a("mi",null,"e"),a("mrow",null,[a("mi",null,"m"),a("mi",null,"u"),a("mi",null,"t")])]),a("mo",{stretchy:"false"},")")]),a("annotation",{encoding:"application/x-tex"},"Concat(h, e_{mut})")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),a("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"C"),a("span",{class:"mord mathnormal"},"o"),a("span",{class:"mord mathnormal"},"n"),a("span",{class:"mord mathnormal"},"c"),a("span",{class:"mord mathnormal"},"a"),a("span",{class:"mord mathnormal"},"t"),a("span",{class:"mopen"},"("),a("span",{class:"mord mathnormal"},"h"),a("span",{class:"mpunct"},","),a("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"e"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t vlist-t2"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.2806em"}},[a("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight"},"m"),a("span",{class:"mord mathnormal mtight"},"u"),a("span",{class:"mord mathnormal mtight"},"t")])])])]),a("span",{class:"vlist-s"},"​")]),a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.15em"}},[a("span")])])])])]),a("span",{class:"mclose"},")")])])]),s("，从而得到分别代表野生型局部环境和突变后局部环境的两种隐藏表示。")],-1),a("p",null,[s("随后，将这两个拼接后的表示分别传入若干注意力块中进行进一步处理。在最终层，我们提取出更新后的"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("msub",null,[a("mi",null,"e"),a("mrow",null,[a("mi",null,"w"),a("mi",null,"t")])])]),a("annotation",{encoding:"application/x-tex"},"e_{wt}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"e"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t vlist-t2"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.2806em"}},[a("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight"},"wt")])])])]),a("span",{class:"vlist-s"},"​")]),a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.15em"}},[a("span")])])])])])])])]),s("和"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("msub",null,[a("mi",null,"e"),a("mrow",null,[a("mi",null,"m"),a("mi",null,"u"),a("mi",null,"t")])])]),a("annotation",{encoding:"application/x-tex"},"e_{mut}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"e"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t vlist-t2"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.2806em"}},[a("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight"},"m"),a("span",{class:"mord mathnormal mtight"},"u"),a("span",{class:"mord mathnormal mtight"},"t")])])])]),a("span",{class:"vlist-s"},"​")]),a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.15em"}},[a("span")])])])])])])])]),s("嵌入表示，计算它们的差值："),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[a("semantics",null,[a("mrow",null,[a("msub",null,[a("mi",null,"e"),a("mrow",null,[a("mi",null,"m"),a("mi",null,"u"),a("mi",null,"t")])]),a("mo",null,"−"),a("msub",null,[a("mi",null,"e"),a("mrow",null,[a("mi",null,"w"),a("mi",null,"t")])])]),a("annotation",{encoding:"application/x-tex"},"e_{mut} - e_{wt}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.7333em","vertical-align":"-0.15em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"e"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t vlist-t2"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.2806em"}},[a("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight"},"m"),a("span",{class:"mord mathnormal mtight"},"u"),a("span",{class:"mord mathnormal mtight"},"t")])])])]),a("span",{class:"vlist-s"},"​")]),a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.15em"}},[a("span")])])])])]),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),a("span",{class:"mbin"},"−"),a("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),a("span",{class:"base"},[a("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),a("span",{class:"mord"},[a("span",{class:"mord mathnormal"},"e"),a("span",{class:"msupsub"},[a("span",{class:"vlist-t vlist-t2"},[a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.2806em"}},[a("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[a("span",{class:"pstrut",style:{height:"2.7em"}}),a("span",{class:"sizing reset-size6 size3 mtight"},[a("span",{class:"mord mtight"},[a("span",{class:"mord mathnormal mtight"},"wt")])])])]),a("span",{class:"vlist-s"},"​")]),a("span",{class:"vlist-r"},[a("span",{class:"vlist",style:{height:"0.15em"}},[a("span")])])])])])])])]),s("，再通过一个线性层映射，最终输出预测的ΔΔG值。")],-1),a("p",null,"该设计使得模型能够专注于比较同一微环境中野生型与突变型氨基酸的差异，利用预训练主干网络对结构环境的深刻理解，实现对突变引起稳定性变化的精确预测。",-1),a("h3",{id:"训练配置",tabindex:"-1"},[s("训练配置 "),a("a",{class:"header-anchor",href:"#训练配置","aria-label":'Permalink to "训练配置"'},"​")],-1),a("p",null,"在训练过程中，我们对训练数据进行随机打乱，并采用Huber损失函数（Huber loss）作为训练损失，其中参数δ设为1。在大规模数据集（如cDNA117K）上进行训练时，我们对模型所有参数进行端到端微调，回归头参数的学习率为5 × 10⁻⁵，主干网络参数的学习率为2 × 10⁻⁵。优化器采用AdamW，批量大小为960（通过每步累积4个梯度实现，实际每批大小为240），权重衰减（weight decay）设为0.1，并使用指数移动平均（EMA）优化策略，衰减率η = 0.99，总训练迭代次数为750次。当将在cDNA数据集上预训练好的模型进一步微调到小规模数据集（如C2878）时，我们冻结主干网络的参数，仅训练回归头部分。此时使用AdamW优化器，学习率为5 × 10⁻⁷，批量大小为1,024，权重衰减仍为0.1，训练迭代500次。若在小数据集上从头开始训练（scratch training），我们也冻结主干网络参数，但将学习率提高至5 × 10⁻⁵，批量大小设为1,024，权重衰减为0.1，训练500轮。",-1),a("h3",{id:"预训练数据集",tabindex:"-1"},[s("预训练数据集 "),a("a",{class:"header-anchor",href:"#预训练数据集","aria-label":'Permalink to "预训练数据集"'},"​")],-1),a("p",null,"我们的图注意力网络主干模型采用与MutComputeX相同的方法进行预训练。具体而言，该预训练数据集来源于RCSB蛋白质数据库（2021年11月版本），从中筛选出22,759条蛋白质序列，这些序列按50%序列相似性聚类，并且其结构分辨率不低于3 Å。从这些结构中采样了共2,569,256个局部微环境，按90:10的比例划分为训练集和验证集。每个微环境以Cα原子为中心，包含一定半径内的原子信息，用于自监督学习任务中预测被掩码位置的氨基酸类型，从而使主干网络充分学习蛋白质结构中的物理化学规律和残基环境偏好。",-1),a("h3",{id:"cdna117k-训练集生成",tabindex:"-1"},[s("cDNA117K 训练集生成 "),a("a",{class:"header-anchor",href:"#cdna117k-训练集生成","aria-label":'Permalink to "cDNA117K 训练集生成"'},"​")],-1),a("p",null,[s("为构建cDNA117K数据集，我们首先从Zenodo知识库的版本1中下载了文件 K50_dG_Dataset1_Dataset2.csv（链接："),a("a",{href:"https://zenodo.org/record/7401275#.Y6st59JBxD_%EF%BC%89%E3%80%82",target:"_blank",rel:"noreferrer"},"https://zenodo.org/record/7401275#.Y6st59JBxD_）。"),s(" 随后，我们移除了所有从头设计（de novo）的蛋白结构，并筛选出在CSV文件中提供了野生型PDB结构ID的单点突变数据。最后，利用这些蛋白的结构序列，通过MMSeqs2的easy-search命令，以30%序列相似性阈值对剩余的微型蛋白（miniproteins）进行过滤，以确保其与测试集T2837无高序列相似性。所使用的命令参数为：-c 0.3 -s 7.5 -seq-id-mode 1。经过此流程，cDNA117K与T2837之间的最高序列相似性为25.4%，满足了低相似性划分的要求。")],-1),a("h3",{id:"c2878-训练集生成",tabindex:"-1"},[s("C2878 训练集生成 "),a("a",{class:"header-anchor",href:"#c2878-训练集生成","aria-label":'Permalink to "C2878 训练集生成"'},"​")],-1),a("p",null,"为构建C2878数据集，我们首先将Q1744、O2567、S2648和FireProtDB四个数据集合并。在合并过程中，针对不同数据集中出现的重复突变条目，我们采用“保留绝对值最大的ΔΔG测量值”的策略进行去重。该策略旨在缓解实验数据中常见的中性突变（ΔΔG ≈ 0）偏差，促使模型预测结果更倾向于表现出明显的稳定化或去稳定化效应，而非趋于中性。完成去重后，我们得到C5266数据集。随后，使用与cDNA117K相同的MMSeqs2命令（-c 0.3 -s 7.5 -seq-id-mode 1），基于结构序列对C5266进行30%序列相似性过滤，以排除与T2837序列相似度过高的样本，最终得到C2878训练集。",-1),a("h3",{id:"t2837-测试集生成",tabindex:"-1"},[s("T2837 测试集生成 "),a("a",{class:"header-anchor",href:"#t2837-测试集生成","aria-label":'Permalink to "T2837 测试集生成"'},"​")],-1),a("p",null,"为构建T2837测试集，我们首先将P53、肌红蛋白（Myoglobin）、SSym 和 S669 四个数据集进行合并。同样地，针对数据集间的重复条目，我们保留ΔΔG绝对值最大的测量值以减少中性偏差。去重后得到T1187数据集。接下来，我们从T1187中移除与C5266（C2878的来源）序列相似性超过30%的样本，得到T2226。最后，将T2226与其他相关数据合并，并采用相同的去重策略处理新增的重复项，最终构建出包含2837个突变样本的T2837测试集。整个过程中，序列相似性过滤均基于蛋白的结构序列，并使用与前述训练集一致的MMSeqs2参数，确保了数据划分的严谨性和无数据泄露。",-1),a("h3",{id:"t2837-alphafold-结构的生成",tabindex:"-1"},[s("T2837 AlphaFold 结构的生成 "),a("a",{class:"header-anchor",href:"#t2837-alphafold-结构的生成","aria-label":'Permalink to "T2837 AlphaFold 结构的生成"'},"​")],-1),a("p",null,"我们对每个PDB ID关联的完整UniProt序列运行了ColabFold 2.3。对于仅TP的“From”和“To”数据集，我们修改了野生型UniProt序列以反映每个突变。我们使用ColabFold的默认参数，并为每条序列选择pLDDT得分最高的折叠PDB结构。",-1),a("h3",{id:"测试集",tabindex:"-1"},[s("测试集 "),a("a",{class:"header-anchor",href:"#测试集","aria-label":'Permalink to "测试集"'},"​")],-1),a("p",null,"为了全面测试不同模型，我们收集并整理了文献中的相关数据集，并构建了我们的测试集。为了获得更多的比较结果，我们在此报告模型在所有文献数据集上的表现。总之，我们在S-sym、P53、Myoglobin和S669数据集上测试了我们的模型。S-sym、P53和Myoglobin数据集由ThermoNet30提出，已被后续研究广泛用作测试基准。S669包含经过整理的数据，其与S2648训练数据在25%序列同一性水平上不相似。此外，我们从原始测试数据中创建了几个新的测试子集：1）交换突变和野生型氨基酸，该测试子集标记为TR；2）当同一位置存在多个单点突变时，我们随机选取其中两个氨基酸作为野生型和突变体，该测试子集标记为TP。",-1),a("h3",{id:"评估指标",tabindex:"-1"},[s("评估指标 "),a("a",{class:"header-anchor",href:"#评估指标","aria-label":'Permalink to "评估指标"'},"​")],-1),a("p",null,"我们采用了回归和分类两类评估指标。首先，为了实现公平比较，我们报告了回归模型的皮尔逊相关系数（Pearson correlation）和均方根误差（RMSE）。此外，在实际应用中，相比于RMSE，我们更关注模型对稳定化突变的预测性能。因此，我们还报告了针对稳定化突变的精确率（precision）和召回率（recall），以及二分类问题的AUROC值（曲线下面积）。",-1),a("h3",{id:"prostata-ifml-细节",tabindex:"-1"},[s("Prostata-IFML 细节 "),a("a",{class:"header-anchor",href:"#prostata-ifml-细节","aria-label":'Permalink to "Prostata-IFML 细节"'},"​")],-1),a("p",null,"我们基于 Prostata 构建了一个强大的序列型基线模型。该基线模型以野生型和突变体序列为输入。两条序列首先被分词，然后分别独立地通过同一个预训练的 ESM2 主干网络。从野生型和突变体序列中分别提取突变位点处的特征表示，并通过外积（outer product）操作来建模野生型与突变体嵌入之间的相互作用。随后将结果展平，并由一个小型解码器预测热力学稳定性的变化量。此结构被称为 PROSTATA 中的“外积变体”（outer-product variant）。",-1),a("p",null,"在训练时，我们使用了与训练 Stability Oracle 相同的 cDNA 数据集。由于 cDNA 蛋白质序列相对较短，我们能够显著增大批量大小至每次 64 个突变，而不同于原始设置中的批量大小 1。模型使用 Adam 优化器训练 3 个周期。训练过程中采用 one-cycle 学习率调度策略：在第一个周期中，学习率从 0 线性增加至 6.4 × 10⁻⁴；在后续周期中，学习率逐步退火至 0。我们在相同的训练集上进行微调，并在上述相同的测试集上评估模型性能。",-1)])]),"main-header":l(()=>[n(t.$slots,"main-header")]),"main-header-after":l(()=>[n(t.$slots,"main-header-after")]),"main-nav":l(()=>[n(t.$slots,"main-nav")]),"main-content":l(()=>[n(t.$slots,"main-content")]),"main-content-after":l(()=>[n(t.$slots,"main-content-after")]),"main-nav-before":l(()=>[n(t.$slots,"main-nav-before")]),"main-nav-after":l(()=>[n(t.$slots,"main-nav-after")]),comment:l(()=>[n(t.$slots,"comment")]),footer:l(()=>[n(t.$slots,"footer")]),aside:l(()=>[n(t.$slots,"aside")]),"aside-custom":l(()=>[n(t.$slots,"aside-custom")]),default:l(()=>[n(t.$slots,"default")]),_:3},8,["frontmatter"])}}};export{f as default};
